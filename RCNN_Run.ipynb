{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32159,
     "status": "ok",
     "timestamp": 1643497910218,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "FsePPpwZSmqt",
    "outputId": "e664a058-5698-4538-c4fe-44adb73855b7"
   },
   "outputs": [],
   "source": [
    "# !pip install pyyaml==5.1\n",
    "\n",
    "# import torch\n",
    "# TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "# CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "# print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# # Install detectron2 that matches the above pytorch version\n",
    "# # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
    "# # If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
    "\n",
    "# # exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1643497933608,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "obLcplOKAfV7"
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "def modify_xml_jpg_file(data_dir, out_dir):\n",
    "    jpg_path = list()\n",
    "    xml_path = list()\n",
    "    file_names = set()\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                if 'checkpoint' in file:\n",
    "                    pass\n",
    "                else:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    file_names.add(os.path.splitext(file_path.split(os.sep)[-1])[0])\n",
    "                    jpg_path.append(file_path)\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xml\"):\n",
    "                if 'checkpoint' in file:\n",
    "                    pass\n",
    "                else:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    file_names.add(os.path.splitext(file_path.split(os.sep)[-1])[0])\n",
    "                    xml_path.append(file_path)\n",
    "    \n",
    "    file_names = sorted(list(file_names))\n",
    "    name_map = dict((n, i) for i, n in enumerate(file_names))\n",
    "    \n",
    "    for xml_file in tqdm(xml_path):\n",
    "        xmlTree = ET.parse(xml_file)\n",
    "        xml_name = os.path.splitext(xml_file.split(os.sep)[-1])[0]\n",
    "        int_name = name_map[xml_name]\n",
    "        rootElement = xmlTree.getroot()\n",
    "        rootElement.findall(\"path\")[0].text = f'{int_name}.jpg'\n",
    "        rootElement.findall(\"filename\")[0].text = f'{int_name}.jpg'\n",
    "\n",
    "        sub_path = os.path.join(*xml_file.split(os.sep)[1:-1])\n",
    "        write_dir = os.path.join(out_dir, sub_path)\n",
    "        if os.path.exists(write_dir):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(write_dir)\n",
    "\n",
    "        write_path = os.path.join(write_dir, str(int_name)+'.xml')\n",
    "        xmlTree.write(write_path, encoding='UTF-8', xml_declaration=True)\n",
    "            \n",
    "    for jpg_file in tqdm(jpg_path):\n",
    "        jpg_name = os.path.splitext(jpg_file.split(os.sep)[-1])[0]\n",
    "        int_name = name_map[jpg_name]\n",
    "\n",
    "        sub_path = os.path.join(*jpg_file.split(os.sep)[1:-1])\n",
    "        write_dir = os.path.join(out_dir, sub_path)\n",
    "        if os.path.exists(write_dir):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(write_dir)\n",
    "        write_path = os.path.join(write_dir, str(int_name)+'.jpg')\n",
    "        shutil.copy2(jpg_file, write_path)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6887,
     "status": "ok",
     "timestamp": 1643497944692,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "pMx1S8tMAiax",
    "outputId": "40e675b3-7497-4769-af80-87bd4bb3f79c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8407/8407 [00:02<00:00, 2975.26it/s]\n",
      "100%|██████████| 8407/8407 [02:21<00:00, 59.29it/s] \n"
     ]
    }
   ],
   "source": [
    "modify_xml_jpg_file('linmao-new', out_dir='linmao-new_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1643497998400,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "M_W5je8GBM80"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_directory = 'linmao-new_processed'\n",
    "\n",
    "train_directory = './train'\n",
    "validation_directory = './validation'\n",
    "\n",
    "os.makedirs(train_directory, exist_ok=True)\n",
    "os.makedirs(validation_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1643498000026,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "4zdtNJK_BP0h",
    "outputId": "5d4f5ff1-e479-4a57-ef7f-f03b4091871d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8406/8406 [05:27<00:00, 25.66it/s] \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "annotation_list = sorted(glob.glob(dataset_directory +'/Annotations'+ '/*.xml'))\n",
    "image_list = sorted(glob.glob(dataset_directory +'/JPEGImages' + '/*.jpg'))\n",
    "\n",
    "file_num = len(annotation_list)\n",
    "\n",
    "index_list = list(range(file_num - 1))\n",
    "random.shuffle(index_list)\n",
    "\n",
    "for count, index in enumerate(tqdm(index_list)):\n",
    "    if count < int(file_num * train_ratio):\n",
    "        shutil.copy2(annotation_list[index], train_directory)\n",
    "        shutil.copy2(image_list[index], train_directory)\n",
    "    else:\n",
    "        shutil.copy2(annotation_list[index], validation_directory)\n",
    "        shutil.copy2(image_list[index], validation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1643498001683,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "9FAugl2eB82J",
    "outputId": "030e97d6-cb83-4a03-c3a5-27a496eed470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of xml files: 6725\n",
      "Success: train/train_annotations.json\n",
      "Number of xml files: 1681\n",
      "Success: validation/validation_annotations.json\n"
     ]
    }
   ],
   "source": [
    "!python voc2coco.py train train/train_annotations.json\n",
    "!python voc2coco.py validation validation/validation_annotations.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1260,
     "status": "ok",
     "timestamp": 1643498006428,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "TGz1IIShCCoW"
   },
   "outputs": [],
   "source": [
    "!mkdir dataset\n",
    "!mkdir dataset/images\n",
    "!mkdir dataset/images/train2017\n",
    "!mkdir dataset/images/val2017\n",
    "!mkdir dataset/images/annotations\n",
    "\n",
    "!cp -rf train/*.jpg dataset/images/train2017\n",
    "!cp -rf validation/*.jpg dataset/images/val2017\n",
    "!cp -rf train/train_annotations.json dataset/images/annotations\n",
    "!cp -rf validation/validation_annotations.json dataset/images/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detect.convert_xml_label_to_txt import convert\n",
    "import os\n",
    "import shutil\n",
    "xml_dir = 'validation'\n",
    "out_dir = f'{xml_dir}_txt'\n",
    "\n",
    "label_map = {'nl_0438': 0,\n",
    "             'nl_0431': 1,\n",
    "             'nl_0239': 2,\n",
    "             'nl_0238': 3,\n",
    "             'nl_0271': 4,\n",
    "             'nl_0280': 5,\n",
    "             'nl_0433': 6,\n",
    "             'nl_0224': 7,\n",
    "             'nl_0098': 8}\n",
    "\n",
    "label_dict = convert(xml_dir, out_dir, label_map, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1764,
     "status": "ok",
     "timestamp": 1643498012098,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "ZyAvNCJMmvFF"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1643497489821,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "AKpRfqT0AT-m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1643497490016,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "JEBFImFSAUA9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1643497490290,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "Qrdt_8ztAUDi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2bjrfb2LDeo"
   },
   "source": [
    "# Train on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjbUIhSxUdm_"
   },
   "source": [
    "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
    "\n",
    "We use [the balloon segmentation dataset](https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon)\n",
    "which only has one class: balloon.\n",
    "We'll train a balloon segmentation model from an existing model pre-trained on COCO dataset, available in detectron2's model zoo.\n",
    "\n",
    "Note that COCO dataset does not have the \"balloon\" category. We'll be able to recognize this new class in a few minutes.\n",
    "\n",
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVJoOm6LVJwW"
   },
   "source": [
    "Register the balloon dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
    "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1643498016689,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "PIbAM2pv-urF"
   },
   "outputs": [],
   "source": [
    "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"linmao_train\", {}, \"dataset/images/annotations/train_annotations.json\", \"dataset/images/train2017\")\n",
    "register_coco_instances(\"linmao_val\", {}, \"dataset/images/annotations/validation_annotations.json\", \"dataset/images/val2017\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "## Train!\n",
    "\n",
    "Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~2 minutes to train 300 iterations on a P100 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 227256,
     "status": "ok",
     "timestamp": 1643498481520,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "qquqvChkH9Ac",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "551c81c3-848e-4305-9a44-5f682c2ffbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/30 01:27:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/30 01:27:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/30 01:27:01 d2.data.datasets.coco]: \u001b[0mLoaded 6725 images in COCO format from dataset/images/annotations/train_annotations.json\n",
      "\u001b[32m[01/30 01:27:02 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 6725 images left.\n",
      "\u001b[32m[01/30 01:27:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/30 01:27:02 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/30 01:27:02 d2.data.common]: \u001b[0mSerializing 6725 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/30 01:27:02 d2.data.common]: \u001b[0mSerialized dataset takes 2.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/30 01:27:02 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[01/30 01:27:02 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n",
      "\u001b[32m[01/30 01:27:02 d2.engine.train_loop]: \u001b[0mStarting training from iteration 300\n",
      "\u001b[32m[01/30 01:27:29 d2.utils.events]: \u001b[0m eta: 1:00:01  iter: 319  total_loss: 0.5568  loss_cls: 0.2017  loss_box_reg: 0.3246  loss_rpn_cls: 0.00448  loss_rpn_loc: 0.01589  time: 1.3253  data_time: 0.2481  lr: 7.992e-05  max_mem: 4943M\n",
      "\u001b[32m[01/30 01:27:56 d2.utils.events]: \u001b[0m eta: 0:59:48  iter: 339  total_loss: 0.5508  loss_cls: 0.2104  loss_box_reg: 0.3226  loss_rpn_cls: 0.001432  loss_rpn_loc: 0.01762  time: 1.3407  data_time: 0.2326  lr: 8.4915e-05  max_mem: 4943M\n",
      "\u001b[32m[01/30 01:28:24 d2.utils.events]: \u001b[0m eta: 0:59:36  iter: 359  total_loss: 0.52  loss_cls: 0.1933  loss_box_reg: 0.2938  loss_rpn_cls: 0.003367  loss_rpn_loc: 0.02015  time: 1.3530  data_time: 0.2279  lr: 8.991e-05  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:28:51 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 379  total_loss: 0.4797  loss_cls: 0.1869  loss_box_reg: 0.2604  loss_rpn_cls: 0.002434  loss_rpn_loc: 0.01086  time: 1.3617  data_time: 0.2320  lr: 9.4905e-05  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:29:19 d2.utils.events]: \u001b[0m eta: 0:59:27  iter: 399  total_loss: 0.535  loss_cls: 0.2116  loss_box_reg: 0.2715  loss_rpn_cls: 0.0009598  loss_rpn_loc: 0.01034  time: 1.3647  data_time: 0.2275  lr: 9.99e-05  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:29:47 d2.utils.events]: \u001b[0m eta: 0:59:21  iter: 419  total_loss: 0.5424  loss_cls: 0.2233  loss_box_reg: 0.3114  loss_rpn_cls: 0.005219  loss_rpn_loc: 0.02047  time: 1.3686  data_time: 0.2335  lr: 0.0001049  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:30:14 d2.utils.events]: \u001b[0m eta: 0:58:57  iter: 439  total_loss: 0.4796  loss_cls: 0.1939  loss_box_reg: 0.2658  loss_rpn_cls: 0.003656  loss_rpn_loc: 0.02146  time: 1.3705  data_time: 0.2246  lr: 0.00010989  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:30:42 d2.utils.events]: \u001b[0m eta: 0:58:30  iter: 459  total_loss: 0.4154  loss_cls: 0.1772  loss_box_reg: 0.2251  loss_rpn_cls: 0.002346  loss_rpn_loc: 0.01007  time: 1.3726  data_time: 0.2335  lr: 0.00011489  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:31:09 d2.utils.events]: \u001b[0m eta: 0:58:03  iter: 479  total_loss: 0.5446  loss_cls: 0.1999  loss_box_reg: 0.29  loss_rpn_cls: 0.002771  loss_rpn_loc: 0.02031  time: 1.3729  data_time: 0.2207  lr: 0.00011988  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:31:37 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 499  total_loss: 0.5004  loss_cls: 0.2111  loss_box_reg: 0.246  loss_rpn_cls: 0.00258  loss_rpn_loc: 0.01589  time: 1.3750  data_time: 0.2362  lr: 0.00012488  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:32:05 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 519  total_loss: 0.4891  loss_cls: 0.186  loss_box_reg: 0.2434  loss_rpn_cls: 0.002433  loss_rpn_loc: 0.01715  time: 1.3745  data_time: 0.2117  lr: 0.00012987  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:32:33 d2.utils.events]: \u001b[0m eta: 0:56:42  iter: 539  total_loss: 0.4673  loss_cls: 0.2102  loss_box_reg: 0.2517  loss_rpn_cls: 0.002205  loss_rpn_loc: 0.01626  time: 1.3762  data_time: 0.2344  lr: 0.00013487  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:33:01 d2.utils.events]: \u001b[0m eta: 0:56:18  iter: 559  total_loss: 0.6355  loss_cls: 0.2343  loss_box_reg: 0.3467  loss_rpn_cls: 0.003385  loss_rpn_loc: 0.0261  time: 1.3781  data_time: 0.2345  lr: 0.00013986  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:33:28 d2.utils.events]: \u001b[0m eta: 0:55:47  iter: 579  total_loss: 0.463  loss_cls: 0.1949  loss_box_reg: 0.2276  loss_rpn_cls: 0.00174  loss_rpn_loc: 0.01561  time: 1.3785  data_time: 0.2329  lr: 0.00014486  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:33:56 d2.utils.events]: \u001b[0m eta: 0:55:23  iter: 599  total_loss: 0.6348  loss_cls: 0.2399  loss_box_reg: 0.3354  loss_rpn_cls: 0.005127  loss_rpn_loc: 0.02663  time: 1.3794  data_time: 0.2355  lr: 0.00014985  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:34:24 d2.utils.events]: \u001b[0m eta: 0:54:55  iter: 619  total_loss: 0.3917  loss_cls: 0.1853  loss_box_reg: 0.2103  loss_rpn_cls: 0.003102  loss_rpn_loc: 0.01379  time: 1.3790  data_time: 0.2288  lr: 0.00015485  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:34:52 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 639  total_loss: 0.448  loss_cls: 0.2002  loss_box_reg: 0.2335  loss_rpn_cls: 0.001123  loss_rpn_loc: 0.01691  time: 1.3803  data_time: 0.2498  lr: 0.00015984  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:35:20 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 659  total_loss: 0.5018  loss_cls: 0.1874  loss_box_reg: 0.2464  loss_rpn_cls: 0.001844  loss_rpn_loc: 0.017  time: 1.3809  data_time: 0.2320  lr: 0.00016484  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:35:48 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 679  total_loss: 0.4843  loss_cls: 0.2164  loss_box_reg: 0.2608  loss_rpn_cls: 0.001245  loss_rpn_loc: 0.01868  time: 1.3818  data_time: 0.2406  lr: 0.00016983  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:36:15 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 699  total_loss: 0.4267  loss_cls: 0.1771  loss_box_reg: 0.23  loss_rpn_cls: 0.001569  loss_rpn_loc: 0.02528  time: 1.3819  data_time: 0.2401  lr: 0.00017483  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:36:42 d2.utils.events]: \u001b[0m eta: 0:52:40  iter: 719  total_loss: 0.4118  loss_cls: 0.1849  loss_box_reg: 0.2182  loss_rpn_cls: 0.001391  loss_rpn_loc: 0.01658  time: 1.3810  data_time: 0.2275  lr: 0.00017982  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:37:10 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 739  total_loss: 0.4556  loss_cls: 0.1782  loss_box_reg: 0.2433  loss_rpn_cls: 0.001396  loss_rpn_loc: 0.01684  time: 1.3808  data_time: 0.2204  lr: 0.00018482  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:37:38 d2.utils.events]: \u001b[0m eta: 0:51:43  iter: 759  total_loss: 0.6007  loss_cls: 0.2475  loss_box_reg: 0.308  loss_rpn_cls: 0.003113  loss_rpn_loc: 0.02394  time: 1.3805  data_time: 0.2141  lr: 0.00018981  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:38:05 d2.utils.events]: \u001b[0m eta: 0:51:16  iter: 779  total_loss: 0.5169  loss_cls: 0.1872  loss_box_reg: 0.2768  loss_rpn_cls: 0.004031  loss_rpn_loc: 0.03318  time: 1.3805  data_time: 0.2150  lr: 0.00019481  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:38:33 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 799  total_loss: 0.4014  loss_cls: 0.1827  loss_box_reg: 0.2065  loss_rpn_cls: 0.001583  loss_rpn_loc: 0.01775  time: 1.3812  data_time: 0.2276  lr: 0.0001998  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:39:00 d2.utils.events]: \u001b[0m eta: 0:50:29  iter: 819  total_loss: 0.3934  loss_cls: 0.1564  loss_box_reg: 0.2001  loss_rpn_cls: 0.0009074  loss_rpn_loc: 0.01585  time: 1.3807  data_time: 0.2296  lr: 0.0002048  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:39:28 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 839  total_loss: 0.427  loss_cls: 0.1714  loss_box_reg: 0.2339  loss_rpn_cls: 0.001585  loss_rpn_loc: 0.01793  time: 1.3810  data_time: 0.2196  lr: 0.00020979  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:39:56 d2.utils.events]: \u001b[0m eta: 0:49:29  iter: 859  total_loss: 0.3427  loss_cls: 0.136  loss_box_reg: 0.1822  loss_rpn_cls: 0.001194  loss_rpn_loc: 0.01819  time: 1.3809  data_time: 0.2228  lr: 0.00021479  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:40:23 d2.utils.events]: \u001b[0m eta: 0:49:01  iter: 879  total_loss: 0.3346  loss_cls: 0.1529  loss_box_reg: 0.1494  loss_rpn_cls: 0.0006764  loss_rpn_loc: 0.01528  time: 1.3807  data_time: 0.2201  lr: 0.00021978  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:40:51 d2.utils.events]: \u001b[0m eta: 0:48:35  iter: 899  total_loss: 0.549  loss_cls: 0.2247  loss_box_reg: 0.2763  loss_rpn_cls: 0.001487  loss_rpn_loc: 0.02039  time: 1.3812  data_time: 0.2325  lr: 0.00022478  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:41:18 d2.utils.events]: \u001b[0m eta: 0:48:03  iter: 919  total_loss: 0.3597  loss_cls: 0.1451  loss_box_reg: 0.1954  loss_rpn_cls: 0.00118  loss_rpn_loc: 0.01248  time: 1.3801  data_time: 0.2219  lr: 0.00022977  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:41:46 d2.utils.events]: \u001b[0m eta: 0:47:37  iter: 939  total_loss: 0.4436  loss_cls: 0.1632  loss_box_reg: 0.233  loss_rpn_cls: 0.002062  loss_rpn_loc: 0.02339  time: 1.3802  data_time: 0.2390  lr: 0.00023477  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:42:13 d2.utils.events]: \u001b[0m eta: 0:47:08  iter: 959  total_loss: 0.401  loss_cls: 0.1477  loss_box_reg: 0.2336  loss_rpn_cls: 0.001135  loss_rpn_loc: 0.01773  time: 1.3798  data_time: 0.2380  lr: 0.00023976  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:42:40 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 979  total_loss: 0.1952  loss_cls: 0.08789  loss_box_reg: 0.1023  loss_rpn_cls: 0.001069  loss_rpn_loc: 0.008262  time: 1.3792  data_time: 0.2227  lr: 0.00024476  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:43:08 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 999  total_loss: 0.4027  loss_cls: 0.1501  loss_box_reg: 0.211  loss_rpn_cls: 0.004105  loss_rpn_loc: 0.02132  time: 1.3791  data_time: 0.2319  lr: 0.00024975  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:43:36 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 1019  total_loss: 0.4105  loss_cls: 0.1593  loss_box_reg: 0.2116  loss_rpn_cls: 0.002035  loss_rpn_loc: 0.02088  time: 1.3790  data_time: 0.2353  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:44:02 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 1039  total_loss: 0.3261  loss_cls: 0.1384  loss_box_reg: 0.1691  loss_rpn_cls: 0.001819  loss_rpn_loc: 0.01497  time: 1.3782  data_time: 0.2242  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:44:30 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 1059  total_loss: 0.2842  loss_cls: 0.1178  loss_box_reg: 0.1596  loss_rpn_cls: 0.0007293  loss_rpn_loc: 0.01226  time: 1.3784  data_time: 0.2478  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:44:57 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 1079  total_loss: 0.3305  loss_cls: 0.1226  loss_box_reg: 0.1856  loss_rpn_cls: 0.001833  loss_rpn_loc: 0.01737  time: 1.3778  data_time: 0.2165  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:45:25 d2.utils.events]: \u001b[0m eta: 0:43:50  iter: 1099  total_loss: 0.3261  loss_cls: 0.1409  loss_box_reg: 0.1795  loss_rpn_cls: 0.001271  loss_rpn_loc: 0.01479  time: 1.3776  data_time: 0.2246  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:45:52 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 1119  total_loss: 0.3791  loss_cls: 0.1505  loss_box_reg: 0.2079  loss_rpn_cls: 0.001454  loss_rpn_loc: 0.02163  time: 1.3775  data_time: 0.2208  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:46:20 d2.utils.events]: \u001b[0m eta: 0:42:56  iter: 1139  total_loss: 0.3288  loss_cls: 0.1459  loss_box_reg: 0.1711  loss_rpn_cls: 0.001105  loss_rpn_loc: 0.01351  time: 1.3778  data_time: 0.2374  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:46:47 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 1159  total_loss: 0.4445  loss_cls: 0.1733  loss_box_reg: 0.2273  loss_rpn_cls: 0.001027  loss_rpn_loc: 0.01495  time: 1.3771  data_time: 0.2085  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:47:15 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 1179  total_loss: 0.4268  loss_cls: 0.1649  loss_box_reg: 0.2377  loss_rpn_cls: 0.002942  loss_rpn_loc: 0.0236  time: 1.3772  data_time: 0.2254  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:47:42 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 1199  total_loss: 0.3853  loss_cls: 0.1571  loss_box_reg: 0.2029  loss_rpn_cls: 0.003057  loss_rpn_loc: 0.01612  time: 1.3768  data_time: 0.2222  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:48:09 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 1219  total_loss: 0.4582  loss_cls: 0.1742  loss_box_reg: 0.253  loss_rpn_cls: 0.001176  loss_rpn_loc: 0.02534  time: 1.3769  data_time: 0.2249  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:48:37 d2.utils.events]: \u001b[0m eta: 0:40:36  iter: 1239  total_loss: 0.4091  loss_cls: 0.159  loss_box_reg: 0.2209  loss_rpn_cls: 0.001839  loss_rpn_loc: 0.02227  time: 1.3769  data_time: 0.2203  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:49:05 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 1259  total_loss: 0.3416  loss_cls: 0.1342  loss_box_reg: 0.1963  loss_rpn_cls: 0.0009595  loss_rpn_loc: 0.01477  time: 1.3769  data_time: 0.2346  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:49:32 d2.utils.events]: \u001b[0m eta: 0:39:40  iter: 1279  total_loss: 0.3048  loss_cls: 0.1202  loss_box_reg: 0.1621  loss_rpn_cls: 0.00132  loss_rpn_loc: 0.01265  time: 1.3768  data_time: 0.2278  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:50:00 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 1299  total_loss: 0.464  loss_cls: 0.1744  loss_box_reg: 0.2541  loss_rpn_cls: 0.0009339  loss_rpn_loc: 0.02839  time: 1.3771  data_time: 0.2300  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:50:27 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 1319  total_loss: 0.3446  loss_cls: 0.1325  loss_box_reg: 0.1975  loss_rpn_cls: 0.0002146  loss_rpn_loc: 0.01593  time: 1.3766  data_time: 0.2222  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:50:55 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 1339  total_loss: 0.3086  loss_cls: 0.133  loss_box_reg: 0.1623  loss_rpn_cls: 0.0007296  loss_rpn_loc: 0.01218  time: 1.3769  data_time: 0.2410  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:51:22 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 1359  total_loss: 0.2672  loss_cls: 0.1148  loss_box_reg: 0.1483  loss_rpn_cls: 0.000563  loss_rpn_loc: 0.01056  time: 1.3770  data_time: 0.2329  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:51:50 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 1379  total_loss: 0.289  loss_cls: 0.1177  loss_box_reg: 0.1525  loss_rpn_cls: 0.001384  loss_rpn_loc: 0.01102  time: 1.3770  data_time: 0.2199  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:52:18 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 1399  total_loss: 0.4084  loss_cls: 0.1456  loss_box_reg: 0.2358  loss_rpn_cls: 0.001819  loss_rpn_loc: 0.0227  time: 1.3770  data_time: 0.2271  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:52:45 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 1419  total_loss: 0.2232  loss_cls: 0.08518  loss_box_reg: 0.1146  loss_rpn_cls: 0.0006183  loss_rpn_loc: 0.00898  time: 1.3773  data_time: 0.2456  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:53:13 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 1439  total_loss: 0.3925  loss_cls: 0.1484  loss_box_reg: 0.2206  loss_rpn_cls: 0.0008201  loss_rpn_loc: 0.01834  time: 1.3772  data_time: 0.2239  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:53:41 d2.utils.events]: \u001b[0m eta: 0:35:33  iter: 1459  total_loss: 0.2892  loss_cls: 0.1098  loss_box_reg: 0.1656  loss_rpn_cls: 0.0008197  loss_rpn_loc: 0.01453  time: 1.3775  data_time: 0.2580  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:54:09 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 1479  total_loss: 0.3687  loss_cls: 0.1332  loss_box_reg: 0.2003  loss_rpn_cls: 0.0009487  loss_rpn_loc: 0.01797  time: 1.3778  data_time: 0.2439  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:54:36 d2.utils.events]: \u001b[0m eta: 0:34:37  iter: 1499  total_loss: 0.3647  loss_cls: 0.1213  loss_box_reg: 0.213  loss_rpn_cls: 0.002081  loss_rpn_loc: 0.02088  time: 1.3777  data_time: 0.2472  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:55:04 d2.utils.events]: \u001b[0m eta: 0:34:11  iter: 1519  total_loss: 0.319  loss_cls: 0.1241  loss_box_reg: 0.1701  loss_rpn_cls: 0.00103  loss_rpn_loc: 0.02017  time: 1.3782  data_time: 0.2521  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:55:31 d2.utils.events]: \u001b[0m eta: 0:33:42  iter: 1539  total_loss: 0.2956  loss_cls: 0.1014  loss_box_reg: 0.1729  loss_rpn_cls: 0.001087  loss_rpn_loc: 0.01943  time: 1.3779  data_time: 0.2171  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:55:59 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 1559  total_loss: 0.3312  loss_cls: 0.1115  loss_box_reg: 0.1966  loss_rpn_cls: 0.001182  loss_rpn_loc: 0.01562  time: 1.3781  data_time: 0.2475  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:56:27 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 1579  total_loss: 0.346  loss_cls: 0.1237  loss_box_reg: 0.1967  loss_rpn_cls: 0.002089  loss_rpn_loc: 0.01882  time: 1.3782  data_time: 0.2343  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:56:54 d2.utils.events]: \u001b[0m eta: 0:32:17  iter: 1599  total_loss: 0.3435  loss_cls: 0.1369  loss_box_reg: 0.19  loss_rpn_cls: 0.001517  loss_rpn_loc: 0.01422  time: 1.3779  data_time: 0.2193  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:57:22 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 1619  total_loss: 0.3446  loss_cls: 0.129  loss_box_reg: 0.1881  loss_rpn_cls: 0.00267  loss_rpn_loc: 0.01871  time: 1.3778  data_time: 0.2325  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:57:50 d2.utils.events]: \u001b[0m eta: 0:31:22  iter: 1639  total_loss: 0.3636  loss_cls: 0.1496  loss_box_reg: 0.1994  loss_rpn_cls: 0.002144  loss_rpn_loc: 0.02201  time: 1.3781  data_time: 0.2514  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:58:17 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 1659  total_loss: 0.3785  loss_cls: 0.141  loss_box_reg: 0.2109  loss_rpn_cls: 0.001253  loss_rpn_loc: 0.02285  time: 1.3782  data_time: 0.2380  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:58:45 d2.utils.events]: \u001b[0m eta: 0:30:28  iter: 1679  total_loss: 0.3438  loss_cls: 0.138  loss_box_reg: 0.1939  loss_rpn_cls: 0.002126  loss_rpn_loc: 0.02155  time: 1.3783  data_time: 0.2363  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:59:13 d2.utils.events]: \u001b[0m eta: 0:30:00  iter: 1699  total_loss: 0.3082  loss_cls: 0.1093  loss_box_reg: 0.1757  loss_rpn_cls: 0.0006086  loss_rpn_loc: 0.01825  time: 1.3785  data_time: 0.2336  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 01:59:40 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 1719  total_loss: 0.2653  loss_cls: 0.103  loss_box_reg: 0.1485  loss_rpn_cls: 0.0001898  loss_rpn_loc: 0.01346  time: 1.3785  data_time: 0.2426  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:00:08 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 1739  total_loss: 0.2032  loss_cls: 0.07729  loss_box_reg: 0.1057  loss_rpn_cls: 0.0003126  loss_rpn_loc: 0.009758  time: 1.3785  data_time: 0.2349  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:00:36 d2.utils.events]: \u001b[0m eta: 0:28:38  iter: 1759  total_loss: 0.4363  loss_cls: 0.1635  loss_box_reg: 0.2404  loss_rpn_cls: 0.002063  loss_rpn_loc: 0.02526  time: 1.3788  data_time: 0.2389  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:01:03 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 1779  total_loss: 0.3425  loss_cls: 0.1156  loss_box_reg: 0.1995  loss_rpn_cls: 0.001069  loss_rpn_loc: 0.01779  time: 1.3785  data_time: 0.2106  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:01:31 d2.utils.events]: \u001b[0m eta: 0:27:42  iter: 1799  total_loss: 0.3326  loss_cls: 0.1104  loss_box_reg: 0.1872  loss_rpn_cls: 0.0009909  loss_rpn_loc: 0.01646  time: 1.3788  data_time: 0.2467  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:01:59 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 1819  total_loss: 0.3587  loss_cls: 0.1359  loss_box_reg: 0.2035  loss_rpn_cls: 0.002592  loss_rpn_loc: 0.0211  time: 1.3787  data_time: 0.2333  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:02:26 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 1839  total_loss: 0.2814  loss_cls: 0.1046  loss_box_reg: 0.1405  loss_rpn_cls: 0.0005003  loss_rpn_loc: 0.01471  time: 1.3788  data_time: 0.2404  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:02:54 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 1859  total_loss: 0.2684  loss_cls: 0.1145  loss_box_reg: 0.1444  loss_rpn_cls: 0.001978  loss_rpn_loc: 0.01726  time: 1.3787  data_time: 0.2340  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:03:22 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 1879  total_loss: 0.3162  loss_cls: 0.1215  loss_box_reg: 0.1838  loss_rpn_cls: 0.0006739  loss_rpn_loc: 0.01667  time: 1.3789  data_time: 0.2412  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:03:50 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 1899  total_loss: 0.2633  loss_cls: 0.09357  loss_box_reg: 0.1566  loss_rpn_cls: 0.002234  loss_rpn_loc: 0.0163  time: 1.3791  data_time: 0.2469  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:04:17 d2.utils.events]: \u001b[0m eta: 0:24:57  iter: 1919  total_loss: 0.2961  loss_cls: 0.1137  loss_box_reg: 0.1838  loss_rpn_cls: 0.001595  loss_rpn_loc: 0.01565  time: 1.3791  data_time: 0.2356  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:04:45 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 1939  total_loss: 0.2855  loss_cls: 0.1079  loss_box_reg: 0.1713  loss_rpn_cls: 0.001387  loss_rpn_loc: 0.01382  time: 1.3795  data_time: 0.2502  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:05:13 d2.utils.events]: \u001b[0m eta: 0:24:02  iter: 1959  total_loss: 0.2792  loss_cls: 0.1273  loss_box_reg: 0.1424  loss_rpn_cls: 0.0008947  loss_rpn_loc: 0.0113  time: 1.3797  data_time: 0.2458  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:05:42 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 1979  total_loss: 0.3189  loss_cls: 0.1114  loss_box_reg: 0.1868  loss_rpn_cls: 0.0004499  loss_rpn_loc: 0.01761  time: 1.3801  data_time: 0.2454  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:06:09 d2.utils.events]: \u001b[0m eta: 0:23:08  iter: 1999  total_loss: 0.3943  loss_cls: 0.1541  loss_box_reg: 0.2184  loss_rpn_cls: 0.001102  loss_rpn_loc: 0.02282  time: 1.3802  data_time: 0.2399  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:06:37 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 2019  total_loss: 0.2595  loss_cls: 0.09606  loss_box_reg: 0.145  loss_rpn_cls: 0.002558  loss_rpn_loc: 0.01659  time: 1.3800  data_time: 0.2474  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:07:04 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 2039  total_loss: 0.1866  loss_cls: 0.06794  loss_box_reg: 0.1112  loss_rpn_cls: 0.001263  loss_rpn_loc: 0.0113  time: 1.3797  data_time: 0.2375  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:07:31 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 2059  total_loss: 0.2779  loss_cls: 0.1082  loss_box_reg: 0.1564  loss_rpn_cls: 0.001419  loss_rpn_loc: 0.01732  time: 1.3795  data_time: 0.2238  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:07:59 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 2079  total_loss: 0.2769  loss_cls: 0.09997  loss_box_reg: 0.1541  loss_rpn_cls: 0.0006537  loss_rpn_loc: 0.01597  time: 1.3795  data_time: 0.2454  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:08:26 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 2099  total_loss: 0.2629  loss_cls: 0.08571  loss_box_reg: 0.1543  loss_rpn_cls: 0.0003901  loss_rpn_loc: 0.01439  time: 1.3796  data_time: 0.2558  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:08:54 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 2119  total_loss: 0.2305  loss_cls: 0.08256  loss_box_reg: 0.1324  loss_rpn_cls: 0.0008684  loss_rpn_loc: 0.01308  time: 1.3795  data_time: 0.2398  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:09:21 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 2139  total_loss: 0.2995  loss_cls: 0.1056  loss_box_reg: 0.1631  loss_rpn_cls: 0.0005003  loss_rpn_loc: 0.01437  time: 1.3795  data_time: 0.2417  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:09:49 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 2159  total_loss: 0.3069  loss_cls: 0.11  loss_box_reg: 0.1812  loss_rpn_cls: 0.0008015  loss_rpn_loc: 0.01948  time: 1.3793  data_time: 0.2456  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:10:16 d2.utils.events]: \u001b[0m eta: 0:18:57  iter: 2179  total_loss: 0.2712  loss_cls: 0.09356  loss_box_reg: 0.1621  loss_rpn_cls: 0.00095  loss_rpn_loc: 0.01812  time: 1.3792  data_time: 0.2379  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:10:43 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 2199  total_loss: 0.2737  loss_cls: 0.09164  loss_box_reg: 0.1484  loss_rpn_cls: 0.00213  loss_rpn_loc: 0.01521  time: 1.3791  data_time: 0.2385  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:11:11 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 2219  total_loss: 0.1936  loss_cls: 0.0799  loss_box_reg: 0.1084  loss_rpn_cls: 0.0008882  loss_rpn_loc: 0.009288  time: 1.3791  data_time: 0.2485  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:11:38 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 2239  total_loss: 0.3596  loss_cls: 0.1309  loss_box_reg: 0.1993  loss_rpn_cls: 0.0009397  loss_rpn_loc: 0.01974  time: 1.3789  data_time: 0.2344  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:12:06 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 2259  total_loss: 0.3101  loss_cls: 0.1094  loss_box_reg: 0.1787  loss_rpn_cls: 0.0006253  loss_rpn_loc: 0.0148  time: 1.3787  data_time: 0.2351  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:12:33 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 2279  total_loss: 0.1899  loss_cls: 0.07871  loss_box_reg: 0.09756  loss_rpn_cls: 0.0006291  loss_rpn_loc: 0.01044  time: 1.3787  data_time: 0.2427  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:13:00 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 2299  total_loss: 0.1867  loss_cls: 0.07149  loss_box_reg: 0.1025  loss_rpn_cls: 0.0007483  loss_rpn_loc: 0.009671  time: 1.3785  data_time: 0.2290  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:13:28 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 2319  total_loss: 0.2721  loss_cls: 0.09366  loss_box_reg: 0.1698  loss_rpn_cls: 0.0008051  loss_rpn_loc: 0.01576  time: 1.3785  data_time: 0.2301  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:13:55 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 2339  total_loss: 0.3764  loss_cls: 0.1331  loss_box_reg: 0.2169  loss_rpn_cls: 0.002011  loss_rpn_loc: 0.02027  time: 1.3785  data_time: 0.2349  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:14:23 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 2359  total_loss: 0.2409  loss_cls: 0.08395  loss_box_reg: 0.1427  loss_rpn_cls: 0.000322  loss_rpn_loc: 0.01274  time: 1.3784  data_time: 0.2400  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:14:50 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 2379  total_loss: 0.245  loss_cls: 0.0993  loss_box_reg: 0.1519  loss_rpn_cls: 0.0009896  loss_rpn_loc: 0.01318  time: 1.3781  data_time: 0.2212  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:15:17 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 2399  total_loss: 0.3202  loss_cls: 0.1087  loss_box_reg: 0.1862  loss_rpn_cls: 0.0009597  loss_rpn_loc: 0.02542  time: 1.3781  data_time: 0.2437  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:15:45 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 2419  total_loss: 0.2783  loss_cls: 0.0995  loss_box_reg: 0.1575  loss_rpn_cls: 0.0003944  loss_rpn_loc: 0.01528  time: 1.3779  data_time: 0.2323  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:16:13 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 2439  total_loss: 0.3234  loss_cls: 0.1067  loss_box_reg: 0.1928  loss_rpn_cls: 0.0005637  loss_rpn_loc: 0.0207  time: 1.3781  data_time: 0.2478  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:16:40 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 2459  total_loss: 0.2441  loss_cls: 0.09147  loss_box_reg: 0.1382  loss_rpn_cls: 0.0006024  loss_rpn_loc: 0.01279  time: 1.3780  data_time: 0.2269  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:17:07 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 2479  total_loss: 0.2241  loss_cls: 0.08205  loss_box_reg: 0.1229  loss_rpn_cls: 0.0001359  loss_rpn_loc: 0.008869  time: 1.3780  data_time: 0.2357  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:17:35 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 2499  total_loss: 0.3415  loss_cls: 0.1255  loss_box_reg: 0.1794  loss_rpn_cls: 0.0006602  loss_rpn_loc: 0.01606  time: 1.3781  data_time: 0.2381  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:18:03 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 2519  total_loss: 0.2586  loss_cls: 0.08815  loss_box_reg: 0.1496  loss_rpn_cls: 0.001463  loss_rpn_loc: 0.01454  time: 1.3783  data_time: 0.2586  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:18:30 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 2539  total_loss: 0.3423  loss_cls: 0.1223  loss_box_reg: 0.2002  loss_rpn_cls: 0.001187  loss_rpn_loc: 0.01804  time: 1.3781  data_time: 0.2279  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:18:58 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 2559  total_loss: 0.2822  loss_cls: 0.09154  loss_box_reg: 0.1611  loss_rpn_cls: 0.001639  loss_rpn_loc: 0.02279  time: 1.3780  data_time: 0.2495  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:19:25 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 2579  total_loss: 0.2879  loss_cls: 0.09563  loss_box_reg: 0.1727  loss_rpn_cls: 0.0005977  loss_rpn_loc: 0.01825  time: 1.3779  data_time: 0.2363  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:19:52 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 2599  total_loss: 0.238  loss_cls: 0.0864  loss_box_reg: 0.1313  loss_rpn_cls: 0.0007588  loss_rpn_loc: 0.01833  time: 1.3777  data_time: 0.2172  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:20:20 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 2619  total_loss: 0.2856  loss_cls: 0.1025  loss_box_reg: 0.1673  loss_rpn_cls: 0.0009235  loss_rpn_loc: 0.02091  time: 1.3777  data_time: 0.2323  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:20:47 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 2639  total_loss: 0.2914  loss_cls: 0.1091  loss_box_reg: 0.1709  loss_rpn_cls: 0.0007683  loss_rpn_loc: 0.01547  time: 1.3775  data_time: 0.2182  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:21:14 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 2659  total_loss: 0.2328  loss_cls: 0.08051  loss_box_reg: 0.1386  loss_rpn_cls: 0.0007549  loss_rpn_loc: 0.01387  time: 1.3774  data_time: 0.2408  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:21:41 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 2679  total_loss: 0.3142  loss_cls: 0.117  loss_box_reg: 0.1827  loss_rpn_cls: 0.0004598  loss_rpn_loc: 0.01743  time: 1.3773  data_time: 0.2270  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:22:08 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 2699  total_loss: 0.3631  loss_cls: 0.1215  loss_box_reg: 0.2125  loss_rpn_cls: 0.0004724  loss_rpn_loc: 0.0173  time: 1.3770  data_time: 0.2211  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:22:36 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 2719  total_loss: 0.242  loss_cls: 0.0853  loss_box_reg: 0.1397  loss_rpn_cls: 0.001178  loss_rpn_loc: 0.01637  time: 1.3771  data_time: 0.2464  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:23:04 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 2739  total_loss: 0.1989  loss_cls: 0.0795  loss_box_reg: 0.113  loss_rpn_cls: 0.0001397  loss_rpn_loc: 0.01299  time: 1.3771  data_time: 0.2446  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:23:31 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 2759  total_loss: 0.2849  loss_cls: 0.09209  loss_box_reg: 0.1679  loss_rpn_cls: 0.00079  loss_rpn_loc: 0.0194  time: 1.3772  data_time: 0.2442  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:23:59 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 2779  total_loss: 0.2296  loss_cls: 0.08056  loss_box_reg: 0.126  loss_rpn_cls: 0.0007316  loss_rpn_loc: 0.01209  time: 1.3771  data_time: 0.2385  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:24:26 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2799  total_loss: 0.2253  loss_cls: 0.07899  loss_box_reg: 0.1258  loss_rpn_cls: 0.001407  loss_rpn_loc: 0.01376  time: 1.3771  data_time: 0.2432  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:24:54 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 2819  total_loss: 0.2757  loss_cls: 0.1007  loss_box_reg: 0.156  loss_rpn_cls: 0.0008653  loss_rpn_loc: 0.01693  time: 1.3773  data_time: 0.2480  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:25:22 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 2839  total_loss: 0.3233  loss_cls: 0.1179  loss_box_reg: 0.1876  loss_rpn_cls: 0.003637  loss_rpn_loc: 0.01858  time: 1.3773  data_time: 0.2344  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:25:49 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 2859  total_loss: 0.2698  loss_cls: 0.09382  loss_box_reg: 0.165  loss_rpn_cls: 0.0005117  loss_rpn_loc: 0.01827  time: 1.3771  data_time: 0.2207  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:26:17 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 2879  total_loss: 0.3343  loss_cls: 0.1208  loss_box_reg: 0.1908  loss_rpn_cls: 0.0007422  loss_rpn_loc: 0.02095  time: 1.3772  data_time: 0.2401  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:26:44 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 2899  total_loss: 0.2484  loss_cls: 0.08881  loss_box_reg: 0.1467  loss_rpn_cls: 0.001141  loss_rpn_loc: 0.01826  time: 1.3773  data_time: 0.2414  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:27:12 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 2919  total_loss: 0.2632  loss_cls: 0.1041  loss_box_reg: 0.143  loss_rpn_cls: 0.0008775  loss_rpn_loc: 0.01608  time: 1.3773  data_time: 0.2342  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:27:40 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 2939  total_loss: 0.1765  loss_cls: 0.06229  loss_box_reg: 0.1057  loss_rpn_cls: 0.0003581  loss_rpn_loc: 0.00997  time: 1.3774  data_time: 0.2334  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:28:06 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2959  total_loss: 0.2933  loss_cls: 0.09046  loss_box_reg: 0.1746  loss_rpn_cls: 0.0007027  loss_rpn_loc: 0.01933  time: 1.3770  data_time: 0.2133  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:28:34 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2979  total_loss: 0.1642  loss_cls: 0.06512  loss_box_reg: 0.09007  loss_rpn_cls: 0.0007969  loss_rpn_loc: 0.009947  time: 1.3770  data_time: 0.2399  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:29:03 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.2327  loss_cls: 0.07886  loss_box_reg: 0.1381  loss_rpn_cls: 0.0002869  loss_rpn_loc: 0.01557  time: 1.3770  data_time: 0.2447  lr: 0.00025  max_mem: 4944M\n",
      "\u001b[32m[01/30 02:29:03 d2.engine.hooks]: \u001b[0mOverall training speed: 2698 iterations in 1:01:55 (1.3770 s / it)\n",
      "\u001b[32m[01/30 02:29:03 d2.engine.hooks]: \u001b[0mTotal training time: 1:01:57 (0:00:02 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"linmao_train\",)\n",
    "cfg.DATASETS.TEST = (\"linmao_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR 0.00025 \n",
    "cfg.SOLVER.MAX_ITER = 3000    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 1280   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 9  # only has one class (ballon)\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2822,
     "status": "error",
     "timestamp": 1643498220001,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "7unkuuiqLdqd",
    "outputId": "adf4d4b1-0c2e-4d1e-ecd8-90e5f7c5cac7"
   },
   "outputs": [],
   "source": [
    "# from detectron2.engine import DefaultTrainer\n",
    "\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "# cfg.DATASETS.TEST = ()\n",
    "# cfg.DATALOADER.NUM_WORKERS = 1\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "# cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "# cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# # NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "# trainer = DefaultTrainer(cfg) \n",
    "# trainer.resume_or_load(resume=False)\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 1208,
     "status": "ok",
     "timestamp": 1643498760613,
     "user": {
      "displayName": "张信",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06176782549426882953"
     },
     "user_tz": 300
    },
    "id": "Ya5nEuMELeq8"
   },
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'dataset/images/val2017'\n",
    "image_path = []\n",
    "\n",
    "for root, dirs, files in os.walk(images_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            if 'checkpoint' in file:\n",
    "                pass\n",
    "            else:\n",
    "                file_path = os.path.join(root, file)\n",
    "                image_path.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1681/1681 [04:53<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "out_put_dir = 'rcnn_pred'\n",
    "os.makedirs(out_put_dir, exist_ok=True)\n",
    "\n",
    "for img_pth in tqdm(image_path):\n",
    "    name = os.path.splitext(img_pth.split(os.sep)[-1])[0]\n",
    "    save_p = os.path.join(out_put_dir, f'{name}.txt')\n",
    "    im = cv2.imread(img_pth)\n",
    "    hight, width = im.shape[:2]\n",
    "    \n",
    "    outputs = predictor(im)\n",
    "    output_data = outputs['instances'].to(\"cpu\")\n",
    "    \n",
    "    boxes = [i.tolist() for i in list(output_data.pred_boxes)]\n",
    "    scores = [i.tolist() for i in list(output_data.scores)]\n",
    "    classes = output_data.pred_classes.tolist()\n",
    "\n",
    "    \n",
    "    result = []\n",
    "    if output_data.has(\"pred_boxes\"):\n",
    "        for idx, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = box[0], box[1], box[2], box[3]\n",
    "            conf = scores[idx]\n",
    "            label = int(classes[idx])\n",
    "            x = (x1 + x2)/2/width\n",
    "            y = (y1 + y2)/2/hight\n",
    "            w = (x2 - x1)/width\n",
    "            h = (y2 - y1)/hight\n",
    "            result.append(f\"{label} {x} {y} {w} {h} {conf}\")\n",
    "        preds = \"\\n\".join(result)  \n",
    "        with open(save_p, \"w+\") as f:\n",
    "            f.write(preds)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 'nl_0438', \n",
    "             1: 'nl_0431', \n",
    "             2: 'nl_0239', \n",
    "             3: 'nl_0238', \n",
    "             4: 'nl_0271', \n",
    "             5: 'nl_0280', \n",
    "             6: 'nl_0433', \n",
    "             7: 'nl_0224', \n",
    "             8: 'nl_0098'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing IoU@0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:23<00:00,  2.66s/it]\n"
     ]
    }
   ],
   "source": [
    "from object_detect.metrics import label_metrics\n",
    "pred_txt_dir = 'rcnn_pred' # runs/detect/combined_yolo_cls/labels\n",
    "truth_txt_dir = 'validation_txt'\n",
    "lm = label_metrics(pred_txt_dir, truth_txt_dir)\n",
    "summary_df = lm.get_metrics(iou_thresholds=[0.5], interpolate_pr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>P@0.5</th>\n",
       "      <th>R@0.5</th>\n",
       "      <th>F1@0.5</th>\n",
       "      <th>AP@0.5</th>\n",
       "      <th>P@All</th>\n",
       "      <th>R@All</th>\n",
       "      <th>F1@All</th>\n",
       "      <th>AP@All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nl_0438</td>\n",
       "      <td>0.976112</td>\n",
       "      <td>0.977945</td>\n",
       "      <td>0.977029</td>\n",
       "      <td>0.976217</td>\n",
       "      <td>0.976112</td>\n",
       "      <td>0.977945</td>\n",
       "      <td>0.977029</td>\n",
       "      <td>0.976217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nl_0431</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.933238</td>\n",
       "      <td>0.871558</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.933238</td>\n",
       "      <td>0.871558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nl_0239</td>\n",
       "      <td>0.930114</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.851133</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.930114</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.851133</td>\n",
       "      <td>0.761111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nl_0238</td>\n",
       "      <td>0.957238</td>\n",
       "      <td>0.978315</td>\n",
       "      <td>0.967777</td>\n",
       "      <td>0.966882</td>\n",
       "      <td>0.957238</td>\n",
       "      <td>0.978315</td>\n",
       "      <td>0.967777</td>\n",
       "      <td>0.966882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nl_0271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nl_0280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nl_0433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877698</td>\n",
       "      <td>0.938849</td>\n",
       "      <td>0.877698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877698</td>\n",
       "      <td>0.938849</td>\n",
       "      <td>0.877698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nl_0224</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.835257</td>\n",
       "      <td>0.752795</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.835257</td>\n",
       "      <td>0.752795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nl_0098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>All</td>\n",
       "      <td>0.638857</td>\n",
       "      <td>0.584095</td>\n",
       "      <td>0.611476</td>\n",
       "      <td>0.578473</td>\n",
       "      <td>0.638857</td>\n",
       "      <td>0.584095</td>\n",
       "      <td>0.611476</td>\n",
       "      <td>0.578473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     P@0.5     R@0.5    F1@0.5    AP@0.5     P@All     R@All  \\\n",
       "0  nl_0438  0.976112  0.977945  0.977029  0.976217  0.976112  0.977945   \n",
       "1  nl_0431  0.994681  0.871795  0.933238  0.871558  0.994681  0.871795   \n",
       "2  nl_0239  0.930114  0.772152  0.851133  0.761111  0.930114  0.772152   \n",
       "3  nl_0238  0.957238  0.978315  0.967777  0.966882  0.957238  0.978315   \n",
       "4  nl_0271  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  nl_0280  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6  nl_0433  1.000000  0.877698  0.938849  0.877698  1.000000  0.877698   \n",
       "7  nl_0224  0.891566  0.778947  0.835257  0.752795  0.891566  0.778947   \n",
       "8  nl_0098  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9      All  0.638857  0.584095  0.611476  0.578473  0.638857  0.584095   \n",
       "\n",
       "     F1@All    AP@All  \n",
       "0  0.977029  0.976217  \n",
       "1  0.933238  0.871558  \n",
       "2  0.851133  0.761111  \n",
       "3  0.967777  0.966882  \n",
       "4  0.000000  0.000000  \n",
       "5  0.000000  0.000000  \n",
       "6  0.938849  0.877698  \n",
       "7  0.835257  0.752795  \n",
       "8  0.000000  0.000000  \n",
       "9  0.611476  0.578473  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.label = summary_df.label.replace(label_map)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAFcCAYAAABfrq6XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/mUlEQVR4nO3de7xcZXX4/88iIQl3CgkICSER5BZEoQH9VUVahRLAcrUg3ugLSykXsUohKFas6DeIFopgKAhiiyBEAiIXL7SgFkvLRQVEQUyoSbgFRERKwm39/njmkMnh5JyTZGb2nNmf9+s1rzmz986s55nM7LVnzbOfHZmJJEmSJEmSetsaVTdAkiRJkiRJ7WcRSJIkSZIkqQYsAkmSJEmSJNWARSBJkiRJkqQasAgkSZIkSZJUAxaBJEmSJEmSasAikGovIs6PiE8OY7ufR8Qe7W+RJGmkiohbIuJDjb+PiIj/rLpNkqTeERFvi4j7h7HdxyPiK51ok0aW0VU3QKpaZh49zO2mtbstkiRJkrQimfkjYNthbPe5DjRHI5AjgdQTIsKCpiRp2MwbktTbunk/381tU++zCKSuFhEPRcQpEXFfRDwVEV+NiHERsUdELIyIkyPiUeCrEbFGRMyMiF9HxJMRcWVEbNT0XG+NiB9HxO8iYkFEHNFYfklEnN74e3xEXNfY5rcR8aOIWKOpLe9s/D02Is6OiIcbt7MjYmxjXV/bPhYRj0fEIxHxV51+7SRJy2vsx0+OiLuBZ/vlhZ81n/IbERs1cs7DjfxzTWP5HzXyxOLG8usiYlI1PZKkkanpmP2ZxnH+gY3lYxv75B2btp0QEc9FxCaNx/tFxE8b2/04InZq2rb/fn70imI1th8VEV+MiCciYn5EHBcR2VekiYgNIuKixvH8oog4PSJGraBPp0XENyPiikasuyLiDUO07c2rkIf2iIiFTdud3GjbMxFxf0S8o6k9lzZt9xdRprf4XZRTl7fv17YTI+LuiHi60YdxK/0fqxHBIpBGgvcCfw5sBWwDnNpY/hpgI2BL4Cjgw8ABwNuBzYGngPMAImIycCPwJWAC8EbgpwPE+hiwsLHNpsDHgRxgu08Ab248zxuA3Zra1de2DYCJwJHAeRHxRyvTaUlSW7wH2Bd4LfAt4HRKLjkRuCoiJjS2+zdgbWAasAlwVmP5GsBXKblnMvAccG6nGi9JPeLXwNsox8ufBi6NiM0ycykwl7Kv7vOXwA8y8/GI2AW4GPgbYGPgX4Br+36Mbejbz2+YmS+uKFZj278GZlCO6XehfJdo9jXgRWBrYGdgL+BDg/Rrf2AOJa9cBlwTEWsO1DbKd43rWfk89IqI2BY4Dtg1M9ejfGd6aIDttgEuBz5C+Z5zA/DtiBjTtNlfAnsDU4GdgCMG6adGMItAGgnOzcwFmflb4LMsSwovA5/KzKWZ+RwlGXwiMxc2EshpwCGNSv57gZsy8/LMfCEzn8zMnw4Q6wVgM2DLxnY/ysyBikDvBf4xMx/PzMWUhPL+fs/zj43nuAH4A8M4d1eS1HbnZOYC4H3ADZl5Q2a+nJnfB+4A9ml8OZgBHJ2ZTzX25T8AaOSPqzLz/zLzGUpeentVnZGkkSgz52Tmw4397xXAryg/qkIpnjQXgQ5vLINStPmXzPzvzHwpM78GLKX8ONvnnMZ3h+eGEesvgX9ufH94CpjV9yQRsSklF3wkM5/NzMcphZjDBunanZn5zcx8AfgnYNwgbVulPNTPS8BYYIeIWDMzH8rMXw+w3aHA9Zn5/UbbvgCsBfxJv7Y93PjO9W1KYUw9yCKQRoIFTX//L2WUD8DizFzStG5L4OrGEMffAb+g7Bg3Bbag/AowlDOBB4HvRcS8iJi5gu02b7RloHYBPNn45aHP/wHrDiO+JKm9+nLKlsC7+3JGI2+8lfJDwBbAbxtfCJYTEWtHxL9ExP9GxO+BHwIbruj0AEnSq0XEB5pO6fodsCMwvrH6P4C1IuJNEbElpRhxdWPdlsDH+u27t2D54/Dm7w5Dxdq83/bNf28JrAk80vRv/4UyKmdFXvn3mfky5QyDFbVtlfJQs8x8kDK65zTg8Yj4RkRsPsCmy313abRtAeWshT6PNv3td5ceZhFII8EWTX9PBh5u/N1/hM4CYEZmbth0G5eZixrrthoqUGY+k5kfy8zXAu8CPtp3Xm0/D1N23AO1S5LUvfpyxwLg3/rljHUyc1Zj3UYRseEA//5jlJGdb8rM9YHdG8uj3Q2XpF7QKOxcSDmNaePM3BC4l8Z+tFGguJIyGuhw4LrGyEso++fP9tt3r52ZlzeFeOU7wlCxgEeA5nndmr93LKCMMhrfFGv9Ia4Y/Mq/jzKv6CSW/47Q/P1lVfPQcjLzssx8K+W7SQJnDLDZct9dIiIabV001POr91gE0khwbERMijLJ88eBK1aw3fnAZxs7+75J5PZvrPs68M6I+MvGJGwbR8Qb+z9BlInmtm7sGH9PGUn00gCxLgdObcQYD/wDcOkA20mSutOlwLsi4s+jTAzad9GBSZn5CGUeuS9HmQh6zYjoK/asR5kH6HeNvPSpitovSSPVOpRixWKAKBdQ2bHfNpdRTmF6L8tOBYNS0Dm6MUooImKdiNg3ItZbxVhXAidExMRGweXkvhWNXPA94IsRsX6Ui9BsFRGDnQL8xxFxUGM6io9Qiki3rWDbVc1Dr4iIbSPizxpzIi2h5KeBvrtcCewbEe9ozFH0sUbbfjxIX9SjLAJpJLiMsgOe17idvoLt/hm4lnIq1zOUHe6bADLzN8A+lB3ebymTQr9hgOd4HXATZQ6f/wK+nJm3DLDd6ZRzdu8G7gHuGqRdkqQu05gXaH/KjwuLKb+6/j3Ljo3eT5nf7ZfA45SDeYCzKfMoPEHJM9/pVJslqRdk5n3AFynH2o8Brwdu7bfNfwPPUk5jurFp+R2UeYHOpVwE5kEGmcB4GLEupHzPuBv4CWXC5BdZVkj5ADAGuK8R75uU07VW5FuU4tVTlDxyUGMOnoHatqp5qNlYyjxGT1BO59qk8Xz9Y91PmYPoS41t3wW8KzOfH6Qv6lEx8Jy3UneIiIeAD2XmTVW3RZIkSVLviogZwPmZueWQG7/6354GbJ2Z72t5w6QWciSQJEmSJKl2ImKtiNinMV3ERMopvlcP9e+kkcwikCRJkiSpjgL4NOX0rZ9Qri78D5W2SGozTweTJEmSJEmqAUcCSZIkSZIk1cDoqgKPHz8+p0yZUlV4Sepad9555xOZOaHqdlTNPCFJAzNPFOYJSRrYYHmisiLQlClTuOOOO6oKL0ldKyL+t+o2dAPzhCQNzDxRmCckaWCD5QlPB5MkSZIkSaoBi0CSJGm13Xor7LQTjB0Lu+wCd9018Haf+xxMmgTrrAOHHgq//31ZngmnnAKbbw7jxsF228EVV3Su/ZLqx/2WpDqyCCR1mQ9/GDbdFCJgv/1WvN0118DWW5eDjj32gPnzO9VCaXkRcXFEPB4R965gfUTEORHxYETcHRG7dKptHuB3xpIlcPDB8MwzcNZZ8NhjcMgh8NJLy2931VXwiU/ArrvCxz8OV14Jp55a1t10E8yaBZttBmeeCYsWwRFHwAsvdLw7klqsG/OE+y1JdWURaBWs7peKodZJhx02+PpHHy3brL9+Oei480744Ac70zZpAJcAew+yfgbwusbtKGB2B9rkAX4H3XhjeX2POabcjjyyFKZvuWX57foen3hiec1f8xq45JKy7OWXy/1WW8Gee8IGG8B668EaHqlIveASuixPuN+SVFfuolZSK75UDLZOOucc+Lu/G3ybyy+HpUvLCIXjj4cDD4Qf/Qh+/evOtFFqlpk/BH47yCb7A/+axW3AhhGxWbvb5QF+5/SNRJw4sdxPmlTu581bfrtNNin3t9wCt98OTzxR8umTT8Jee8Gxx8KcObD99mXZZZfBqFEd6YKkNurGPOF+q/NW94f0004rI+X73yStHA9jV1IrvlQMtk4ajuEeuEhdYiKwoOnxwsayV4mIoyLijoi4Y/HixasV1AP86mSW+/4H53/7t+WUulNPhd12K6fYQbm//3649NLyms+dW06LPeIIePbZjjZdUjUqyRPN3G+1Vyt+SD/kkPJD6OWXw7nnlmU779zZfki9wCLQSmrFl4rB1kmrYkUHLlKXGOidmQNtmJkXZOb0zJw+YcKEljbCA/z2mTq13C9cWO4XLVq2fMkSeP758nj8ePjZz0rue+CBMtfS5Mnl195rr4Wnn4b3v7+MbnznO8vz3Hdf5/sjqeM6nifcb3VWK35I33HHMh3CYYfBc8+VZUcf3aEOSD1kdNUNGOkG+1Jx2WXlS8Wpp8K668If/lC+VAy2TlqRJUvKKShjxgx+4CJ1oYXAFk2PJwEPtzvoUAf4fZ+nvgP8u+8up3vtt19ZP9AB/vXXw0UXlQP8XXdtdw9Gjhkzyg8cs2eX0+UuugimTCmT1o8eDdOmwb33wsMPl19vt9kGvvOd8oXqnHPKc2y1VbmfPbsc3F933fL7O0k9reN5wv1WZw32Q/o73rFsu+Yfy8eMKT+Wv/hi+bF8443Luky44IIyN+bhh3ek+VJPGXIkUDfO5t+niqu+tOJXg8HWSddfv+x9uGABfOUr8KtfwVprlfc5lF9AxoyBM86AL30Jrr4a3vrWZQcjUpe5FvhAI1+8GXg6Mx9pd9DmA/zZs5c/wG/+PD38cJln4N574ZOfLPvlE08s65oP8C+80AP8FRk3rpwyt+66cMIJ5XWfM+fVp82tsUbZX/3N38APfwif+hQcd1xZd9BBcNJJ8NBDZa6zjTYqo7DGj+94dyR1XsfzhPutaq3K6Nw+N99cjo3f977y/ydpJWXmoDdgd2AX4N4VrN8HuJEyjPPNwH8P9ZyZyR//8R/n6njuucxNN82cMiXzvPMyN988c+rUzBdfXH67b34zEzIPOCDz9NPL38cfX9Z973vl8S67ZJ5zTua662aOG5f5/PODx91kkxL3y18ucadMKXEhc9q0st2iRZmnnJL51a9mHnpoWXfOOUOvk97+9vKeaL599avLv78yM6+6KvO1r80cMybzbW/LfPDBqlqsVgPuyGHsR7vlBlwOPAK8QPk190jgaODoxvoAzgN+DdwDTB/O865unsjM/MEPMnfcMXPNNTPf+MbM22/ve42XfZ4eeSRzu+3KZ2mzzTI/9anMl18u615+OfOkk8q+fuzYzO23z7zyytVuliStFvNE6/KEOmPu3JJ7zzijPP7kJ8vjm24q36+WLl227dKlJV8/8EDmNttkTp68/HO9+93l3959d+faL400g+WJIU8Hy8wfRsSUQTZ5ZTZ/4LaI2DAiNss2V+/7ziv9/OfLeaWPPgqf+UwZOtg8pLD5vNK3vKUM57zkkjKMs/9VX844o4zkGeyqL32/Ghx7bPnVYNq08uvwin41mDevDF1s/tVgsHVS/3Oj+xxxxPKPDzqo3KSqZeZ7hlifwLEdas5ydt8d7rnn1cuzaaaJ17wGfvGLgf99RMkNZ5zRnvZJUh10c55QZ7Ti9DuAxx+Ha64p3+te//qKOiONcK2YE2hFs/m/qggUEUcBRwFMnjx5tYK24rzSvqu+nHdeKeyMGwff/vbQV31Z3S8Vg61TvU2ZeX1bn/+hWfu29fmlbuFnqXPa/VqDr7ek1jNPdFYrfkgHuPhieOEFJ4SWVkcrrg7mVV8kSZIkSSvU90P688/DT34C06eX5ZllFBAs+7F86dJlc/Y1f7+bObNs/773dbz5Us9oxUigWl31pa6/Gtx6aymo3X9/qdx/5SvLJlVt9rnPwZe/DE89VV7rCy8sM/dDmeT4uOPgppvKsM/99oOvf72z/ZAkSZIkqa5aUQS6FjguIr4BvIkKrvriZR3ba8kSOPjgcjWds86Cz34WDjmkzMrfPITzqqvgE5+AAw4olf1TTy2jq845p1TsDzywFNhOOgk228xT4iRJkqRe52nDUncZziXiLwf+C9g2IhZGxJERcXRE9J2JeQMwD3gQuBA4pm2tbeJlHTunbxLuY44ptyOPLHMy9Z/AuHkS7k98ogznvOSSsuzmm+HOO+GjHy3DOI86Cs4+u3N9kCRJkiSp7oZzdbCunc3fq750Rism4b7vvrLuqqvKKWPrrFNGFH34wx3pgiRJkiRJtdeK08E6rq7z8nSLwSbhvuyychrYqaeWUVp/+EMZtbV0adlmzTXLyKxPfhI+8hHYe+9yqp4kSZIkSWqvVlwdTD1uqEm4n3++PO6bhPv228vcS5tvDpMnl1E/U6aUbfbdF/bfv9xnLhtlJEmSJEmS2mtEjgRSZ7ViEu599inPcdVVsPXW8M1vlpFCO+9cZc8kSZIkSaoPRwKNMLfeCjvtBGPHlku033XXwNt97nNl7p511oFDD4Xf/74sX7wY3vjGsny99eDtby8FnMG0YhLutdYqhZ+xY+HYY2HttWHu3GXzCEmSJEmSpPZyJNAI0opLtUMZ2fN3fwc//zmceWa5Ytf3vjd47NWdhBvgbW8b+DkkSZIkSVL7WQQaQfou1f75z5dLtT/6KHzmM+VqXM1X6Wq+VPtb3lJO0brkklIEmjABTj8dfvvbUhg688wygmdF2j0JNzgRtyRJkiRJnWARaARpxaXaN964jMbpm4tn4kQ4++xOtF6SJEmSJFXJOYFGsMEu1b7dduU0sN12K3P6wLL7rbeG7363jCJ6+OEyskiSJEmSJPU2i0AjSCsu1Q5lgue99ipFoi22gCuv7Gw/JEmSJElS53k62AjSiku1f/Wr8NOfliuE3X03/OY3sOuu1fVJkiRJkiR1hkWgEaTvUu3HHlsu1T5tGlx44Yov1T5vXpkDqPlS7RMmwA03wPnnlxFB++0H//RPne+LJEmSJEnqLE8HG2H6LtX+/PPwk5+US8BDmR/o3nvL332Xal+6tIwKOu20ZfMG7bdfuaT80qVlouhvfxte97pKuiJJklbBrbfCTjvB2LGwyy5w112v3iYTTjmlnBI+blyZK/CKK4ZeJ0ka+cwTGowjgUaIdl+q3cu0S5LU/ZYsgYMPhrXWgrPOgs9+Fg45pPzA0zwy+KabYNascvB/yinw8Y/DEUfAQQeVq4euaN2aa1bUMalmbr21XMzl/vvL6P6vfKV8Jptlls/n174Gv/1tmQbi05+GQw8tP/J++tOvft6+C8eovswTGoojgSS9YnV/NQD43Odg0qQyEfmhh8Lvf9+59kvdYnU/S30jOPvfpBtvhMceg2OOKbcjj4T588sBe7OXXy73W20Fe+4JG2xQ5hNcY43B10lqv74v6c88U76kP/ZY+ZL+0kvLb9f3JX2zzeDMM8tFYY44Al54oWx/+eXldu65Zfudd+54V9SFzBMaiv+NkoDWHJBcdRV84hNlsvGPf7xcee7UUyvpjlQZD+7VTvPnl/uJE8v9pEnlft685bfba68yh+CcObD99uUU8MsuK78CD7ZOUvu14kv6jjvCYYeV23PPle2OPrqj3VCXMk9oKBaBJAGtOSDp2/bEE0sx6DWvgUsu6WAnpC7gwb06qe/Uj/4jxe6/Hy69tBzIz50Lm25aiozPPjv4Oknt14ov6X0y4YILYP314fDD2992jTzmCfVnEUgS0JoDkk02Kdvccgvcfjs88UQZDfHkkx3pgtQVPLhXO02dWu4XLiz3ixYtW75kSblwBMC118LTT8P73w8HHgjvfGfZ9r77Bl8nqfNW5Ut6n5tvLnO9vO995cq/knlCQ7EIJGlAq3JA8rd/W+Y1OfVU2G23Ms8JLLuX6siDe7XSjBml4D57drlddFGZLHaPPcokoH0Ty261VbmfPRsuvBCuuw7GjClfAgZbJ6n9WvElvc/555d7R4uqj3lCQ7EIJAlozQHJ+PHws5+VUUAPPFAmvJ08uUwSLdWFB/dqp3HjyuixddeFE04oB/pz5rx6noaDDoKTToKHHoLjj4eNNipFx/HjB18nqf1a8SUd4PHH4Zpr4C1vgde/voKOqCuZJzQULxEvCVj+gGS99ZY/IBk9uly+9N57lz8gee655Q9IHn64TGK7zTbwne+UQtA551TZK6nzWvFZAg/utWK77w733PPq5c2Xho6AM84ot/4GWyep/fq+pB97bPmSPm1aKfKs6Ev6pZeWL+KvfS186UvLvohffHG5mIA/FKg/84QGYxFIEtCaA5JHH4Wrry5zn2y8MXzqU3DccdX0R6qKB/eSpKGs7pd0gJkzy01qNmXm9W19/odm7dvW51f7WQSS9IrVPSB5zWvgF79oX/ukkcKDe7WLB/eSJGl1WASS1PYvFeAXC9WDnyVJ0mDME5Kq5sTQkiRJkiRJNWARSJIkSZIkqQYsAkmSJEmSJNWARSBJkiRJkqQasAgkSZIkSZJUAxaBJEmSJEmSasAikCRJkiRJUg1YBJIkSZIkSaoBi0CSJEmSJEk1YBFIkiRJkiSpBiwCSZIkSZIk1YBFIEmSJEmSpBqwCCRJkiRJklQDFoEkSZIkSZJqwCKQJEmShuXWW2GnnWDsWNhlF7jrrldvc9ppEPHqG0AmnHIKbL45jBsH220HV1zR0S5IklRrFoEkSastIvaOiPsj4sGImDnA+g0i4tsR8bOI+HlE/FUV7ZS06pYsgYMPhmeegbPOgsceg0MOgZdeWn67Qw6Byy8vt3PPLct23rnc33QTzJoFm20GZ54JixbBEUfACy90tCuqgHlCkrqDRSBJ0mqJiFHAecAMYAfgPRGxQ7/NjgXuy8w3AHsAX4yIMR1taA2s7iiNwdZJN95YCj/HHFNuRx4J8+fDLbcsv92OO8Jhh5Xbc8+VZUcfXe5ffrncb7UV7LknbLABrLcerOERaU8zT0hS9zDlSpJW127Ag5k5LzOfB74B7N9vmwTWi4gA1gV+C7zY2Wb2tlaM0hhsnTR/frmfOLHcT5pU7ufNG3j7TLjgAlh/fTj88LJsr73g2GNhzhzYfnt48km47DIYNaq9bVflzBOS1CUsAkmSVtdEYEHT44WNZc3OBbYHHgbuAU7IzJf7P1FEHBURd0TEHYsXL25Xe3tSK0ZpDLZO6i+z3K9otNjNN8OvfgXvex+su25Zdv/9cOmlpRg0dy5sumk5HezZZzvSZFXHPCFJXcIikCRpdQ30FTD7Pf5z4KfA5sAbgXMjYv1X/aPMCzJzemZOnzBhQqvb2dNaMUpjOOtUX1OnlvuFC8v9okXLli9ZAs8/v/z2559f7psLiddeC08/De9/Pxx4ILzzneV57ruvvW1X5cwTXWJ1TxsGWLAA9t8f1lmnnNL53vd2rPmSWmD0cDaKiL2BfwZGAV/JzFn91m8AXApMbjznFzLzqy1uqySpOy0Etmh6PInyS26zvwJmZWYCD0bEfGA74H8608T6Ge4ojWOOWTZKYzjrVF8zZsAmm8Ds2WUen4sugilTYI89YPRomDYN7r23bPv443DNNfCWt8DrX7/sObbaqtzPnl1Gm113HYwZs6zApJ5lnugCfacNr7VWOW34s58tpwH/6lfLn5J5yCHlyn1QTtk87rhlpwZnlgLufffBSSeVSd5/8YvO90XSqhtyJJATuUmShnA78LqImNrY9x8GXNtvm98A7wCIiE2BbYEVjFHRqmjFKI3hrFN9jRtX5vJZd1044YRSEJozZ+D5fC6+uFzxq/976KCDyhfHhx6C44+HjTYqp4eNH9+RLqg65oku0IrThm++Ge68Ez76UZg5E446Cs4+u5O9ULdrxWiz/ssPOKBTra+H4YwEemUiN4CI6JvIrXngrhO5SVJNZeaLEXEc8F3KiNGLM/PnEXF0Y/35wGeASyLiHsppASdn5hOVNboHtWKUxlDrpN13h3vuefXy7Hdiz8yZ5dZfBJxxRrmpPswT3WGw04bf8Y5Xbz/QqcF9p25edRV87nPllLDPfhY+/OH2tl0jQytGm/U5+OCyHSx7r6o1hlMEGmgitzf12+ZcSjX/YWA94NAVTeQGHAUwefLkVWmvJKkLZeYNwA39lp3f9PfDwF6dbled9I3SOPbYMkpj2jS48MKVG6Ux1DpJWlXmie6zKqcNL11a7tdcE66+Gj75SfjIR2DvvWGbbdreZHW5vtFmn/98ed88+ih85jNltFlzoXHHHcsN4AtfKPf9jzt22AHe9a5SaFRrDacItDITuf0ZsBXw/Yj4UWb+frl/lHkBcAHA9OnT+z+HJElaDas7SmOodaqvKTOvb3uMh2bt2/YYUp0NddrwGmuUObr6DHRq8JQp5X7ffcvk0LfdVvLO/PkWgdSa0WZ9Tj+9FJAmT4bzzoP99mtfu+tmOEUgJ3KTJEmSpBGsFacN77NPeY6rroKtt4ZvfrOMEup/Ko8Eq36RipNPhje/GRYvho99DN7znjLCaO2129/mOhhOEeiVidyARZSJ3PpfMLZvIrcfOZGbJEmd1+6RGo7SkKSRrRWnDa+1Vin8HHNMeZ5tt4W5c0thSGrFaDOAWU3XIv/Od8p7bMGC8n7T6huyCOREbpIkSZI08rXitOG3vW3g55BaMdrshhvKVSP32AOeeqrMMzRhwrICk1bfcEYCOZGbJEmSJI1gjhhVu7VitNmWW8Ijj8BJJ8FLL8H06fDFLy4/gkirZ1hFIEmSJEmSpMGs7mizadPKXEFqH4tAkiRJkiRplTnSbORYo+oGSJIkSZIkqf0sAkmSJEmSJNWARSBJkiRJkqQasAgkSZIkSZJUAxaBJEmSJEmSasAikCRJkiRJUg1YBJIkSZIkSaoBi0CSJEmSJEk1YBFIkiRJkiSpBiwCSZIkSZIk1YBFIEmSJEmSpBqwCCRJkiRJklQDFoEkSZIkSZJqwCKQJEmSJElSDVgEkiRJkiRJqgGLQJIkSZIkSTVgEUiSJEmSJKkGLAJJkiRJkiTVgEUgSZIkSZKkGrAIJEmSJEmSVAMWgSRJkiRJkmrAIpAkSZIkSVINWASSJEmSJEmqAYtAkiRJkiRJNWARSFKt3Xor7LQTjB0Lu+wCd9018HYLFsD++8M668AGG8B737v8+sWLYfx4iIAvfKH97ZYkSZKklWURSFJtLVkCBx8MzzwDZ50Fjz0GhxwCL720/HaZcOCB8P3vw9//PXz+8zBhwvLbnHACPPdc59ouSZIkSSvLIpCk2rrxxlL4OeaYcjvySJg/H265Zfntbr4Z7rwTPvpRmDkTjjoKzj57+ef59rfh5JM72XpJkiRJWjkWgSTV1vz55X7ixHI/aVK5nzdv+e3uu6/cX3UVrL02rL8+nHNOWfaHP8DRR8P/+38weXL72yxJkiRJq8oikCQ1ZJb7iOWXL11a7tdcE66+GqZOhY98BB54AM44oxSG9toLHn+8bPfkk/DUUx1rtiRJkiQNy+iqGyBJVZk6tdwvXFjuFy1atnzJElhjDRgzBqZMKcv33bdMDn3bbXDPPWUk0YIF8MtfwrbbLnveWbPKBNKnntqxrkiSJEnSkCwCSaqtGTNgk01g9mxYbz246KJS8NljDxg9GqZNg3vvhX32KdtddRVsvTV885uw7rqw886w8caw337l+W65Bc47Dz7wgTLBtCRJkiR1E08Hk1Rb48bBnDmloHPCCaXQM2cOjBq1/HZrrVUKP2PHwrHHltO/5s4t20+fXgo+hxxS/gZ4/ethu+063x9JkiRJGowjgSTV2u67l1O7+uubH6jP29428HbNjjii3CRJkiSpGzkSSJIkSZIkqQYcCSSplqbMvL7tMR6atW/bY0iSJEnScDkSSJIkSVqBW2+FnXYq88LtsgvcddfA20UsfzvggLI8E045BTbfvMxFt912cMUVHWu+JEnLsQgkSZIkDWDJEjj4YHjmGTjrLHjssXIhgJdeGnj7gw+Gyy8vtxNPLMtuuglmzYLNNoMzz4RFi8r8cS+80LFuSJLaZCT+UGARSJK02iJi74i4PyIejIiZK9hmj4j4aUT8PCJ+0Ok2StLKuvHGUvg55phyO/JImD8fbrll4O132AHe9S447DB461vLspdfLvdbbQV77gkbbADrrQdr1Owo3DwhqdeM1B8KapZ+JEmtFhGjgPOAGcAOwHsiYod+22wIfBn4i8ycBry70+2UpJU1f365nzix3E+aVO7nzRt4+9NPh3XXhS23hOuuK8v22guOPRbmzIHtt4cnn4TLLoNRo9rb9m5inpDUi0bqDwUWgSRJq2s34MHMnJeZzwPfAPbvt83hwNzM/A1AZj7e4TZK0mrLLPcRr1538skwdy5ccAE89RS85z3wf/8H998Pl15aikFz58Kmm5ZfeZ99tqNNr5p5QlLPGak/FFgEkiStronAgqbHCxvLmm0D/FFE3BIRd0bEBwZ6oog4KiLuiIg7Fi9e3KbmStLwTJ1a7hcuLPeLFi1bvmQJPP/8sm1nzSpzPPz1X5dfc//wB1iwAK69Fp5+Gt7/fjjwQHjnO8vz3HdfR7tSNfOEpJ43Un4oGNYl4iNib+CfgVHAVzJz1gDb7AGcDawJPJGZb29ZKyVJ3WyAVEf2ezwa+GPgHcBawH9FxG2Z+cBy/yjzAuACgOnTp/d/DknqqBkzYJNNYPbsMjz/ootgyhTYYw8YPRqmTYN774UbbigH8XvsUQ7ub7wRJkwoxaKttirPNXs2PPdc+fV3zJhlBaaaME9I6jlD/VCwxhplfw/lh4I+3/lOKfgM9EPB9deXXHPffbDrru1p95BFoKZzePekVO1vj4hrM/O+pm02pJzDu3dm/iYiNmlPcyVJXWghsEXT40nAwwNs80RmPgs8GxE/BN4APIAkdalx48oQ/WOPhRNOKEWfCy989TD9LbeERx6Bk04qE4JOnw5f/GI5+D/ooLL80kvh+OPhta+FL30Jxo+vpk8VMU9I6jkj9YeC4YwEeuUcXoCI6DuHt3kQq+fwSlJ93Q68LiKmAouAwyh5odm3gHMjYjQwBngTcFZHWylJq2D33eGee169PJvGoEybBjffPPC/j4Azzii3GjNPSOo5I/WHguEUgQY6h/dN/bbZBlgzIm4B1gP+OTP/tf8TRcRRwFEAkydPXpX2SpK6TGa+GBHHAd+lnDZ8cWb+PCKObqw/PzN/ERHfAe4GXqacWnxvda2WJHWKeUJSrxqJPxQMpwjkObySpEFl5g3ADf2Wnd/v8ZnAmZ1slyStqikzr2/r8z80a9+2Pn+3MU9IUncYThHIc3glSZIkSZIaRuqPBcO5RPwr5/BGxBjKObzX9tvmW8DbImJ0RKxNOV3sF61tqiRJkiRJklbVkCOBPIdXkiRJkiRp5BvO6WCewytJkiRJkjTCDed0MEmSJEmSJI1wFoEkSZIkSZJqwCKQJEmSJElSDVgEkiRJkiRJqgGLQJIkSZIkSTVgEUiSJEmSJKkGLAJJkiRJkiTVgEUgSZIkSZKkGrAIJEmSJEmSVAMWgSRJkiRJkmrAIpAkSZIkSVINWASSJEmSJEmqAYtAkiRJkiRJNWARSJIkSZIkqQYsAkmSJEmSJNWARSBJkiRJkqQasAgkSZIkSZJUAxaBJEmSJEmSasAikCRJkiRJUg1YBJIkSZIkSaoBi0CSJEmSJEk1YBFIkiRJkiSpBiwCSZIkSZIk1YBFIEmSJEmSpBqwCCRJkiRJklQDFoEkSZIkSZJqwCKQJEmSJElSDVgEkiRJkiRJqgGLQJIkSZIkSTVgEUiSJEmSJKkGLAJJkiRJkiTVgEUgSZIkSZKkGrAIJEmSJEmSVAMWgSRJkiRJkmrAIpAkSZIkSVINWASSJEmSJEmqAYtAkiRJkiRJNWARSJIkSZIkqQYsAkmSJEmSJNWARSBJkiRJkqQasAgkSVptEbF3RNwfEQ9GxMxBtts1Il6KiEM62T5JUrXME5LUHSwCSZJWS0SMAs4DZgA7AO+JiB1WsN0ZwHc720JJUpXME5LUPYZVBLJyL0kaxG7Ag5k5LzOfB74B7D/AdscDVwGPd7JxkqTKmSckqUsMWQSyci9JGsJEYEHT44WNZa+IiInAgcD5gz1RRBwVEXdExB2LFy9ueUMlSZUwT0hSlxjOSCAr95KkwcQAy7Lf47OBkzPzpcGeKDMvyMzpmTl9woQJrWqfJKla5glJ6hKjh7HNQJX7NzVv0FS5/zNg15a1TpI0EiwEtmh6PAl4uN8204FvRATAeGCfiHgxM6/pSAslSVUyT0hSlxhOEWilKveNHffATxRxFHAUwOTJk4fZRElSl7sdeF1ETAUWAYcBhzdvkJlT+/6OiEuA6zywl6TaME9IUpcYThGoZZX7zLwAuABg+vTp/QtJkqQRKDNfjIjjKHPCjQIuzsyfR8TRjfWDzu8gSept5glJ6h7DKQJZuZckDSozbwBu6LdswIP6zDyiE22SJHUP84QkdYchi0BW7iVJkiRJkka+4YwEsnIvSZIkSZI0wg3nEvGSJEmSJEka4SwCSZIkSZIk1YBFIEmSJEmSpBqwCCRJkiRJklQDFoEkSZIkSZJqwCKQJEmSJElSDVgEkiRJkiRJqgGLQJIkSZIkSTVgEUiSJEmSJKkGLAJJkiRJkiTVgEUgSZIkSZKkGrAIJEmSJEmSVAMWgSRJkiRJkmrAIpAkSZIkSVINWASSJEmSJEmqAYtAkiRJkiRJNWARSJIkSZIkqQYsAkmSJEmSJNWARSBJkiRJkqQasAgkSZIkSZJUAxaBJEmSJEmSasAikCRJkiRJUg1YBJIkSZIkSaoBi0CSJEmSJEk1YBFIkiRJkiSpBiwCSZIkSZIk1YBFIEmSJEmSpBqwCCRJkiRJklQDFoEkSZIkSZJqwCKQJEmSJElSDVgEkiRJkiRJqgGLQJIkSZIkSTVgEUiSJEmSJKkGLAJJkiRJkiTVgEUgSZIkSZKkGrAIJEmSJEmSVAMWgSRJkiRJkmrAIpAkSZIkSVINWASSJEmSJEmqAYtAkiRJkiRJNWARSJIkSZIkqQYsAkmSJEmSJNWARSBJ0mqLiL0j4v6IeDAiZg6w/r0RcXfj9uOIeEMV7ZQkVcM8IUndYVhFIHfakqQViYhRwHnADGAH4D0RsUO/zeYDb8/MnYDPABd0tpWSpKqYJySpewxZBHKnLUkawm7Ag5k5LzOfB74B7N+8QWb+ODOfajy8DZjU4TZKkqpjnpCkLjGckUDutCVJg5kILGh6vLCxbEWOBG4caEVEHBURd0TEHYsXL25hEyVJFTJPSFKXGE4RyJ22JGkwMcCyHHDDiD+l5ImTB1qfmRdk5vTMnD5hwoQWNlGSVCHzhCR1ieEUgdxpS5IGsxDYounxJODh/htFxE7AV4D9M/PJDrVNklQ984QkdYnhFIHcaUuSBnM78LqImBoRY4DDgGubN4iIycBc4P2Z+UAFbZQkVcc8IUldYvQwtnllpw0souy0D2/ewJ22JNVXZr4YEccB3wVGARdn5s8j4ujG+vOBfwA2Br4cEQAvZub0qtosSeoc84QkdY8hi0DutCVJQ8nMG4Ab+i07v+nvDwEf6nS7JEndwTwhSd1hOCOB3GlLkiRJkiSNcMOZE0iSJEmSJEkjnEUgSZIkSZKkGrAIJEmSJEmSVAMWgSRJkiRJkmrAIpAkSZIkSVINWASSJEmSJEmqAYtAkiRJkiRJNWARSJIkSZIkqQYsAkmSJEmSJNWARSBJkiRJkqQasAgkSZIkSZJUAxaBJEmSJEmSasAikCRJkiRJUg1YBJIkSZIkSaoBi0CSJEmSJEk1YBFIkiRJkiSpBiwCSZIkSZIk1YBFIEmSJEmSpBqwCCRJkiRJklQDFoEkSZIkSZJqwCKQJEmSJElSDVgEkiRJkiRJqgGLQJIkSZIkSTVgEUiSJEmSJKkGLAJJkiRJkiTVgEUgSZIkSZKkGrAIJEmSJEmSVAMWgSRJkiRJkmrAIpAkSZIkSVINWASSJEmSJEmqAYtAkiRJkiRJNWARSJIkSZIkqQYsAkmSJEmSJNWARSBJkiRJkqQasAgkSZIkSZJUAxaBJEmSJEmSasAikLrarbfCTjvB2LGwyy5w110Db3fNNbD11jBuHOyxB8yfP7Jj142vtaRVZZ6oB19rSavKPFEPvtbDZxFIXWvJEjj4YHjmGTjrLHjsMTjkEHjppeW3e/RROOwwWH99OPNMuPNO+OAHR27suvG1lrSqzBP14GstaVWZJ+rB13rlWARS17rxxvIBPuaYcjvyyFKpveWW5be7/HJYuhROOQWOPx4OPBB+9CP49a9HZuy68bWWtKrME/Xgay1pVZkn6sHXeuVYBFLX6huaN3FiuZ80qdzPm7dq242U2HXjay1pVZkn6sHXWtKqMk/Ug6/1yrEIpBEjs9xHtGa7kRK7bnytJa0q80Q9+FpLWlXmiXrwtR6cRSB1ralTy/3CheV+0aJly5csgeefH3q7kRi7bnytJa0q80Q9+FpLWlXmiXrwtV45o6tugLQiM2bAJpvA7Nmw3npw0UUwZUqZxX30aJg2De69t0zuNXMmnHFGORf06qvhrW+FrbYambHrxtda0qoyT9SDr7WkVWWeqAdf65UzrJFAEbF3RNwfEQ9GxMwB1kdEnNNYf3dE7NL6pqpuxo2DOXNg3XXhhBPKB3vOHBg1avntNtusTPL1u9/BiSfCzjvDJZeM3Nh142vdG8wTqoJ5oh58rXuDeUJVME/Ug6/1yhlyJFBEjALOA/YEFgK3R8S1mXlf02YzgNc1bm8CZjfupdWy++5wzz2vXt53/mafgw4qt16JXTe+1iObeUJVMk/Ug6/1yGaeUJXME/Xgaz18wxkJtBvwYGbOy8zngW8A+/fbZn/gX7O4DdgwIjZrcVslSd3JPCFJGox5QpK6RGT/0lj/DSIOAfbOzA81Hr8feFNmHte0zXXArMz8z8bjfwdOzsw7+j3XUcBRjYfbAve3qiNDGA880aFY3RLbPtcjdt3iVhm7k3G3zMwJHYq12swTIza2fe79uFXGts/tZZ4ozBPG7ZXY9rkesbsiTwxnYuiBLpjWv3I0nG3IzAuAC4YRs6Ui4o7MnN7puFXGts/1iF23uFXGrrLPI4B5YgTGts+9H7fK2PZZ/ZgnRmDsusWtMrZ9rkfsbskTwzkdbCGwRdPjScDDq7CNJKk3mSckSYMxT0hSlxhOEeh24HURMTUixgCHAdf22+Za4AONWf3fDDydmY+0uK2SpO5knpAkDcY8IUldYsjTwTLzxYg4DvguMAq4ODN/HhFHN9afD9wA7AM8CPwf8Ffta/Iq6fiQ0S6IbZ/rEbtucauMXWWfu5p5YsTGts+9H7fK2PZZrzBPjNjYdYtbZWz7XI/YXZEnhpwYWpIkSZIkSSPfcE4HkyRJkiRJ0ghnEUiSJEmSJKkGLAJJkiRJkiTVgEUgSZIkSZKkGrAIJGmVRMQmVbdBktS9zBOSpMGYJ6rRk0WgiJgeETdHxKURsUVEfD8ino6I2yNi54radGObn3/diPjHiPh5o6+LI+K2iDiizXHr+FpvEBGzIuKXEfFk4/aLxrIN2xj3NRExOyLOi4iNI+K0iLgnIq6MiM3aFbcRe6N+t42B/4mIP4qIjdoYt+Pvr4j4dkRcu6JbO2Kq8+q276oqRzRi1+q1bjy/ecI8oRGsG/dbjXaZJzrEPNGW2OaJLskTo6tuQJt8GfgUsCHwY+DvMnPPiHhHY93/146gEbHLilYBb2xHzCZfB64G/hz4S2Ad4BvAqRGxTWZ+vE1x6/haXwn8B7BHZj7aaM9rgA8Cc4A92xT3EuB6yv/tzZT/832B/YHzG/ft8gTwv/2WTQTuAhJ4bZviVvH++kIbnlPdp277rqpyBNTvtQbzRB/zhEaqSvZbYJ7APGGeaD3zRD+RmVW3oeUi4ieZuXPj799k5uSB1rUh7kvADyg7jv7enJlrtSNuI/bPMvMNTY9vz8xdI2IN4L7M3K5Ncev4Wt+fmduu7LoWxB3stf5pZr6xHXEbz38i8E7g7zPznsay+Zk5tV0xGzEqeX+p99Vt31VVjmjEqtVr3YhtnsA8oZGryveVecI8YZ5oeVzzRD+9OhJoSUTsBWwAZEQckJnXRMTbgZfaGPcXwN9k5q/6r4iIBW2MC/BsRLw1M/8zIt4F/BYgM1+OiIF2bK1Sx9f6fyPiJOBrmflYI+amwBFAO2M3n775r4Osa7nM/EJEfAM4q/H6fopSsW+3jr+/IuIeBu5bAC83HyBpRKvbvquqHAH1e63BPGGe0EhX1X4LzBPmCfNEq5kn+unVItDRwOeBlylDGv82Ii4BFgF/3ca4p7HiD8/xbYwLpc9fiYhtgXuAIwEiYgJwXpvj1u21PhSYCfwglk1m9hhwLWX4bLt8KyLWzcw/ZOapfQsjYmvggTbGBSAzFwLvbhwYfB9Yu90xqeb9td8AywKYBLRzKLQ6q277rqpyRF/sOr3WYJ4wT2ikq2q/BeYJ84R5otXME/0b0oung0lqr4hYC9gqM++tui3tFBFvBA6nJOP5wFWZeW6ljZKkEcA8IUkajHmiOr06EoiI2A3IzLw9InYA9gZ+kZntnul9oLi/zMwb2hm3ythVvNYR8WFgbqOa3FERMQY4DFiUmf8eEYcDf0IZUnpBZr7QxthVvr+2o0ze9t+Z+Qfg3sbyvTPzO22MuxVwILAF8CLwK+CyzPx9m+JtQ/n/fQ/wJHAFpWD+p+2Ip+rULU90YX4yT7QntnnCPKEWqCpHDBLbPNH6mOYJ80Qt80RPjgSKiE8BMyhFru8DbwJuoUxE9d3M/Gwvxa0ydoVxnwaeBX4NXA7MyczF7Yg1QOyvU/q7NvA7YF1gLvAOymfqg22KW+X768PAsZTE9EbghMz8VmPdXZm5oqsrtCLuuyiT9u0D/BR4irITPyYzb2lDzJeBHwFHZuaDjWXzMrNdVyxQBWq4z6xjfjJPmCfME1olNd1n1rHP5gnzRD3zRGb23I1yHusoyofq98D6jeVrAXf3Wtw69hn4CeUc3r2Ai4DFwHcol1Vcr82v9d2N+9GUc3dHNR5HL77WTbHXbfw9BbiDsuMG+Em7+9z4e23glsbfk9sVl5IQrqBMynchJRnPb+fr663ztxruM6vef5gn0jzRzj43/jZPeGvV/3HVnyXzRGf6bJ4wT7QlbrfnibbOAF6hFzPzpcz8P+DX2RjmlZnPUSaE6rW4VcauKm5m5suZ+b3MPBLYHPgyZTjjvDbGBVijMYRzPcqOZIPG8rHAmm2MW+X7a1SWIZtk5kPAHsCMiPgnBr6sZiv1nbY6lvKak5m/oU2vdWZenZmHAttRfhn5O2DTiJgd5coC6g1122fWMT+ZJ8wT5gmtqjruM+vYZ/OEeaKWeaJXi0DPR0TfTON/3LcwIjagvW/uquJWGbuquMvtKDLzhcy8NjPfQ6nqttNFwC8pQwk/AcyJiAuB24FvtDFule+vRxuTmgHQ2IHvB4wHXt/GuF8Bbo+IC4D/As6FV65U8ds2xiUzn83Mr2fmfpSZ/H9KuYqDekPd9pl1zE/miQbzRHuYJ3paHfeZdeyzeaLBPNEe3ZonenVOoLGZuXSA5eOBzTLznl6KW2XsCuNuk5ltv4zhIPE3B8jMhyNiQ8p5tL/JzP9pY8wq31+TKL8cPDrAurdk5q1tjD0N2B64NzN/2a44qpca7jPrmJ/ME8uWmyeklVDTfWYd+2yeWLbcPFEjPVkEGkhE/EVmXluXuKqHury/ImJTypUEEng4Mx+ruEnqQeYJ9aK6vL/ME2q3Kj9Ldfkcqxp1eX+ZJ5bpyUvER8RB/RcB50XEaIDMnNtLcRuxdwIuoLyxbwROzsynGuv+JzN367G4r6dMstXRuI3nr6rPVb6/Knm9G0NGz6ecJ72osXhSRPyOMpv/Xe2Iq95XtzxR1X6rytjmibII84R5Qiut4s+SecI8YZ5obdw3Yp5YTk8WgYArKTO7P86ycz3XoVwaLimX3+uluFAmMTsNuA34EPCfjarur2nv5GJVxZ1dUVyors9Vvr+qer0vAf4mM/+7eWFEvBn4KvCGNsZWb6tbnqhqv1VlbPNEYZ6QVl6VnyXzhHnCPNFal2CeWF52wSXKWn0DdgX+Hfhblp3yNr9X4zbi/LTf4z8FfgW8GbjLuCM/dk3fX78aZN2Dnei7t9681S1P1HSfWcc+myeWX2ee8LZKt4o/S+YJ84R5orVxzRP9bj15dbDMvB3YExgD/EdE7EapbPZk3IaIMqt7X1tuBg4G/g3Y0rgjP3ZN3183RsT1EXFoRPxJ43ZoRFxP+RVDWiU1zBO122dWGLey2OYJ84Rao8rPknnCPNHO2OYJ8wTUYGLoiJgInAVMz8zX9mrciDgcmJeZt/VbPhn4ZGb+tXFHfuymWLV4fzVizAD2p5w/HMBC4NrMvKFdMVUvdcgTddxn1rHP/WKZJ8wTaoGqckSnY9dxn1nHPveLZZ6oaZ7o+SKQJEmSJEmSenRi6Mbs5kcCBwKb07gMHPAt4KLMfKGX4lYZu25xq4xd8z4fQNMlHdsdV72vC97TtYhbZWz7XLs+H4B5Qi1S88+SfbbPbdEFfT4A8wTQoyOBIuJy4HfA1yhDvQAmAR8ENsrMQ3spbpWx6xa3ytj2ubN9Vm+r23va/Yd9bmfcKmObJ9QOfpbsczvjVhnbPpsnoHeLQPdn5rYrWPdAZm7TS3GrjF23uFXGts+di6veV7f3tPuPzsWtMrZ97lxc9TY/S52LW2Vs+9y5uFXGNk+8Wk9eHQx4KiLeHRGv9C8i1oiIQ4GnejBulbHrFrfK2Pa5c3HV++r2nnb/0bm4Vca2z52Lq97mZ6lzcauMbZ87F7fK2OaJ/rILrlPf6hswBbgCWAw80Lg93lg2tdfi1rHPvtb2ud199tbbt7q9p91/2Gf77M3b8G9+luyzfe6d2OaJV9968nSwZhGxMeW0tycGWLdnZn6/l+JWGbtucauMbZ87F1e9r27vafcfnYtbZWz73Lm46m1+ljoXt8rY9rlzcauMbZ4oer4INJiIuCszd6lL3Cpj1y1ulbHts9Q6dXtPu/+oR2z7LLWGn6V6xLbP9YhdpzzRq3MCDVfULG6VsesWt8rY9llqnbq9p91/1CO2fZZaw89SPWLb53rErk2eqHsRqKphUFUOv6pbn32t6xG7vkMa1W51e0+7/6hHbPsstYafpXrEts/1iF2bPFH3IpAkSZIkSVIt1L0I9FDN4lYZu25xq4xdVdwqY1cVV73vIeP2fOyq4lYZu6q4VcauKq5620M1jF1V3CpjVxW3ythVxa0ydlVxO64nJ4aOiIMGW5+Zc3spbpWx6xa3ytj2uXNx1fvq9p52/9G5uFXGts+di6ve5mepc3GrjG2fOxe3ytjmiVcbXXUD2uRd/R73Vbqi8Xe7/qOriltl7LrFrTK2fe5sn9Xb6vaedv9hn+2zNHx+luyzfe6d2OaJfnqyCJSZfwUQEeOAg4EpLOtr24Y+VRW3yth1i1tlbPvc2T6rt9XtPe3+wz63M26Vsc0Tagc/S/a5nXGrjG2fzRPQo0WgJtcAvwPuApY0lnXiP7qquFXGrlvcKmNXFbfK2FXFVe+7hnq9p6uKW2XsquJWGbuquFXGriquets1+FnqVNwqY1cVt8rYVcWtMnZVcbtOT84J1Cci7s3MHesSt8rYdYtbZWz7LLVO3d7T7j/qEds+S63hZ6kese1zPWKbJ5bp9auD/TgiXl+juFXGrlvcKmPbZ6l16vaedv9Rj9j2WWoNP0v1iG2f6xHbPNHQ6yOB7gO2BuYDS2lM/pSZO/Vi3Cpj1y1ulbHtc2f7rN5Wt/e0+w/73M64VcY2T6gd/CzZ53bGrTK2fa53nuj1ItCWAy3PzP/txbhVxq5b3Cpj2+fOxVXvq9t72v1H5+JWGds+dy6uepufpc7FrTK2fe5c3CpjmyeW6ekikCRJkiRJkopenxNIkiRJkiRJWASSJEmSJEmqBYtAkiRJkiRJNWARSJIkSZIkqQb+f/ESN+CA4bRHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(131)\n",
    "x = [str(i) for i in summary_df['label']]\n",
    "precisions = summary_df['P@0.5'].tolist()\n",
    "plt.title('precision')\n",
    "plt.bar(x, precisions)\n",
    "plt.xticks(rotation=90)\n",
    "for i, v in enumerate(x):\n",
    "    plt.text(i-0.4, precisions[i]+0.01, str(round(precisions[i], 2)), color='blue', fontweight='bold')\n",
    "\n",
    "plt.subplot(132)\n",
    "recalls = summary_df['R@0.5'].tolist()\n",
    "plt.title('recall')\n",
    "plt.bar(x, recalls)\n",
    "plt.xticks(rotation=90)\n",
    "for i, v in enumerate(x):\n",
    "    plt.text(i-0.4, recalls[i]+0.01, str(round(recalls[i], 2)), color='blue', fontweight='bold')\n",
    "\n",
    "plt.subplot(133)\n",
    "aps = summary_df['AP@0.5'].tolist()\n",
    "plt.title('average precision')\n",
    "plt.bar(x, aps)\n",
    "plt.xticks(rotation=90)\n",
    "for i, v in enumerate(x):\n",
    "    plt.text(i-0.4, aps[i]+0.01, str(round(aps[i], 2)), color='blue', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Detectron2_Tutorial.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
